[2019-02-18 20:34:32,720] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-02-18 20:34:32,744] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-02-18 20:34:32,744] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-02-18 20:34:32,745] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-02-18 20:34:32,745] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-02-18 20:34:32,760] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-02-18 20:34:32,761] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-02-18 20:34:37,332] INFO Server environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-02-18 20:34:37,333] INFO Server environment:host.name=DESKTOP-6IV0LP1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-02-18 20:34:37,334] INFO Server environment:java.version=1.8.0_201 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-02-18 20:34:37,334] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-02-18 20:34:37,334] INFO Server environment:java.home=C:\Program Files\Java\jdk1.8.0_201\jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-02-18 20:34:37,335] INFO Server environment:java.class.path=D:\Software\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;D:\Software\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;D:\Software\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;D:\Software\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;D:\Software\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;D:\Software\kafka_2.12-2.1.0\libs\compileScala.mapping;D:\Software\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;D:\Software\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\guava-20.0.jar;D:\Software\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;D:\Software\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;D:\Software\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;D:\Software\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;D:\Software\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;D:\Software\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;D:\Software\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;D:\Software\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;D:\Software\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;D:\Software\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;D:\Software\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;D:\Software\kafka_2.12-2.1.0\libs\javax.inject-1.jar;D:\Software\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;D:\Software\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;D:\Software\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;D:\Software\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;D:\Software\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;D:\Software\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;D:\Software\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;D:\Software\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;D:\Software\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;D:\Software\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;D:\Software\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;D:\Software\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;D:\Software\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;D:\Software\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;D:\Software\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;D:\Software\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;D:\Software\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;D:\Software\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;D:\Software\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;D:\Software\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;D:\Software\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;D:\Software\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;D:\Software\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;D:\Software\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;D:\Software\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;D:\Software\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;D:\Software\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;D:\Software\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-02-18 20:34:37,336] INFO Server environment:java.library.path=C:\Program Files\Java\jdk1.8.0_201\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;%JAVA_HOME%\bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Users\Administrator\AppData\Local\Microsoft\WindowsApps;;. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-02-18 20:34:37,337] INFO Server environment:java.io.tmpdir=C:\Users\ADMINI~1\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-02-18 20:34:37,337] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-02-18 20:34:37,338] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-02-18 20:34:37,339] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-02-18 20:34:37,339] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-02-18 20:34:37,340] INFO Server environment:user.name=Administrator (org.apache.zookeeper.server.ZooKeeperServer)
[2019-02-18 20:34:37,340] INFO Server environment:user.home=C:\Users\Administrator (org.apache.zookeeper.server.ZooKeeperServer)
[2019-02-18 20:34:37,340] INFO Server environment:user.dir=D:\Software\kafka_2.12-2.1.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-02-18 20:34:37,383] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-02-18 20:34:37,383] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-02-18 20:34:37,384] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-02-18 20:34:37,424] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-02-18 20:34:37,440] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-02-18 20:34:46,490] INFO Expiring session 0x10001ad58720000, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-02-18 20:34:46,492] INFO Processed session termination for sessionid: 0x10001ad58720000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-18 20:34:46,493] INFO Creating new log file: log.b8 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-02-18 20:35:06,254] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-02-18 20:35:06,912] INFO starting (kafka.server.KafkaServer)
[2019-02-18 20:35:06,914] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-02-18 20:35:06,936] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-02-18 20:35:11,464] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-02-18 20:35:11,465] INFO Client environment:host.name=DESKTOP-6IV0LP1 (org.apache.zookeeper.ZooKeeper)
[2019-02-18 20:35:11,465] INFO Client environment:java.version=1.8.0_201 (org.apache.zookeeper.ZooKeeper)
[2019-02-18 20:35:11,465] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-02-18 20:35:11,466] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_201\jre (org.apache.zookeeper.ZooKeeper)
[2019-02-18 20:35:11,466] INFO Client environment:java.class.path=D:\Software\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;D:\Software\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;D:\Software\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;D:\Software\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;D:\Software\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;D:\Software\kafka_2.12-2.1.0\libs\compileScala.mapping;D:\Software\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;D:\Software\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\guava-20.0.jar;D:\Software\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;D:\Software\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;D:\Software\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;D:\Software\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;D:\Software\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;D:\Software\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;D:\Software\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;D:\Software\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;D:\Software\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;D:\Software\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;D:\Software\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;D:\Software\kafka_2.12-2.1.0\libs\javax.inject-1.jar;D:\Software\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;D:\Software\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;D:\Software\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;D:\Software\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;D:\Software\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;D:\Software\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;D:\Software\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;D:\Software\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;D:\Software\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;D:\Software\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;D:\Software\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;D:\Software\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;D:\Software\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;D:\Software\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;D:\Software\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;D:\Software\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;D:\Software\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;D:\Software\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;D:\Software\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;D:\Software\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;D:\Software\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;D:\Software\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;D:\Software\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;D:\Software\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;D:\Software\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;D:\Software\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;D:\Software\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;D:\Software\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.ZooKeeper)
[2019-02-18 20:35:11,468] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_201\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;%JAVA_HOME%\bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Users\Administrator\AppData\Local\Microsoft\WindowsApps;;. (org.apache.zookeeper.ZooKeeper)
[2019-02-18 20:35:11,468] INFO Client environment:java.io.tmpdir=C:\Users\ADMINI~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-02-18 20:35:11,469] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-02-18 20:35:11,470] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-02-18 20:35:11,471] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-02-18 20:35:11,471] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-02-18 20:35:11,471] INFO Client environment:user.name=Administrator (org.apache.zookeeper.ZooKeeper)
[2019-02-18 20:35:11,472] INFO Client environment:user.home=C:\Users\Administrator (org.apache.zookeeper.ZooKeeper)
[2019-02-18 20:35:11,472] INFO Client environment:user.dir=D:\Software\kafka_2.12-2.1.0 (org.apache.zookeeper.ZooKeeper)
[2019-02-18 20:35:11,476] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@78b66d36 (org.apache.zookeeper.ZooKeeper)
[2019-02-18 20:35:11,528] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-02-18 20:35:11,528] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-02-18 20:35:11,533] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-02-18 20:35:11,533] INFO Accepted socket connection from /127.0.0.1:55109 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-02-18 20:35:11,562] INFO Client attempting to establish new session at /127.0.0.1:55109 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-02-18 20:35:11,583] INFO Established session 0x1000573f3780000 with negotiated timeout 6000 for client /127.0.0.1:55109 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-02-18 20:35:11,585] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1000573f3780000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-02-18 20:35:11,593] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-02-18 20:35:11,803] INFO Got user-level KeeperException when processing sessionid:0x1000573f3780000 type:create cxid:0x1 zxid:0xba txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-18 20:35:11,868] INFO Got user-level KeeperException when processing sessionid:0x1000573f3780000 type:create cxid:0x2 zxid:0xbb txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-18 20:35:11,889] INFO Got user-level KeeperException when processing sessionid:0x1000573f3780000 type:create cxid:0x3 zxid:0xbc txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-18 20:35:11,901] INFO Got user-level KeeperException when processing sessionid:0x1000573f3780000 type:create cxid:0x4 zxid:0xbd txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-18 20:35:11,913] INFO Got user-level KeeperException when processing sessionid:0x1000573f3780000 type:create cxid:0x5 zxid:0xbe txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-18 20:35:11,926] INFO Got user-level KeeperException when processing sessionid:0x1000573f3780000 type:create cxid:0x6 zxid:0xbf txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-18 20:35:11,938] INFO Got user-level KeeperException when processing sessionid:0x1000573f3780000 type:create cxid:0x7 zxid:0xc0 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-18 20:35:11,951] INFO Got user-level KeeperException when processing sessionid:0x1000573f3780000 type:create cxid:0x8 zxid:0xc1 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-18 20:35:11,963] INFO Got user-level KeeperException when processing sessionid:0x1000573f3780000 type:create cxid:0x9 zxid:0xc2 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-18 20:35:11,976] INFO Got user-level KeeperException when processing sessionid:0x1000573f3780000 type:create cxid:0xa zxid:0xc3 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-18 20:35:11,988] INFO Got user-level KeeperException when processing sessionid:0x1000573f3780000 type:create cxid:0xb zxid:0xc4 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-18 20:35:12,000] INFO Got user-level KeeperException when processing sessionid:0x1000573f3780000 type:create cxid:0xc zxid:0xc5 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-18 20:35:12,012] INFO Got user-level KeeperException when processing sessionid:0x1000573f3780000 type:create cxid:0xd zxid:0xc6 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-18 20:35:12,334] INFO Cluster ID = 5Tl4DeAbRCSXBvJrXLLt7Q (kafka.server.KafkaServer)
[2019-02-18 20:35:12,461] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-02-18 20:35:12,469] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-02-18 20:35:12,511] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-02-18 20:35:12,511] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-02-18 20:35:12,515] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-02-18 20:35:12,613] INFO Loading logs. (kafka.log.LogManager)
[2019-02-18 20:35:12,785] WARN [Log partition=first-topic-0, dir=D:\tmp\kafka-logs] Found a corrupted index file corresponding to log file D:\tmp\kafka-logs\first-topic-0\00000000000000000000.log due to Corrupt time index found, time index file (D:\tmp\kafka-logs\first-topic-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1550482327278}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-02-18 20:35:12,789] INFO [Log partition=first-topic-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:12,898] INFO [ProducerStateManager partition=first-topic-0] Writing producer snapshot at offset 514 (kafka.log.ProducerStateManager)
[2019-02-18 20:35:12,917] INFO [Log partition=first-topic-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-02-18 20:35:12,919] INFO [Log partition=first-topic-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:12,961] INFO [ProducerStateManager partition=first-topic-0] Writing producer snapshot at offset 514 (kafka.log.ProducerStateManager)
[2019-02-18 20:35:13,058] INFO [Log partition=first-topic-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 514 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:13,061] INFO [ProducerStateManager partition=first-topic-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\first-topic-0\00000000000000000514.snapshot' (kafka.log.ProducerStateManager)
[2019-02-18 20:35:13,095] INFO [Log partition=first-topic-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 514 in 398 ms (kafka.log.Log)
[2019-02-18 20:35:13,141] WARN [Log partition=first-topic-1, dir=D:\tmp\kafka-logs] Found a corrupted index file corresponding to log file D:\tmp\kafka-logs\first-topic-1\00000000000000000000.log due to Corrupt time index found, time index file (D:\tmp\kafka-logs\first-topic-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1550487023393}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-02-18 20:35:13,141] INFO [Log partition=first-topic-1, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:13,159] INFO [ProducerStateManager partition=first-topic-1] Writing producer snapshot at offset 155 (kafka.log.ProducerStateManager)
[2019-02-18 20:35:13,161] INFO [Log partition=first-topic-1, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-02-18 20:35:13,161] INFO [Log partition=first-topic-1, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:13,177] INFO [ProducerStateManager partition=first-topic-1] Writing producer snapshot at offset 155 (kafka.log.ProducerStateManager)
[2019-02-18 20:35:13,206] INFO [Log partition=first-topic-1, dir=D:\tmp\kafka-logs] Loading producer state till offset 155 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:13,207] INFO [ProducerStateManager partition=first-topic-1] Loading producer state from snapshot file 'D:\tmp\kafka-logs\first-topic-1\00000000000000000155.snapshot' (kafka.log.ProducerStateManager)
[2019-02-18 20:35:13,208] INFO [Log partition=first-topic-1, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 155 in 92 ms (kafka.log.Log)
[2019-02-18 20:35:13,226] WARN [Log partition=msg-topic-0, dir=D:\tmp\kafka-logs] Found a corrupted index file corresponding to log file D:\tmp\kafka-logs\msg-topic-0\00000000000000000000.log due to Corrupt time index found, time index file (D:\tmp\kafka-logs\msg-topic-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1550487113073}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-02-18 20:35:13,227] INFO [Log partition=msg-topic-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:13,245] INFO [ProducerStateManager partition=msg-topic-0] Writing producer snapshot at offset 30 (kafka.log.ProducerStateManager)
[2019-02-18 20:35:13,247] INFO [Log partition=msg-topic-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-02-18 20:35:13,248] INFO [Log partition=msg-topic-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:13,262] INFO [ProducerStateManager partition=msg-topic-0] Writing producer snapshot at offset 30 (kafka.log.ProducerStateManager)
[2019-02-18 20:35:13,289] INFO [Log partition=msg-topic-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 30 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:13,290] INFO [ProducerStateManager partition=msg-topic-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\msg-topic-0\00000000000000000030.snapshot' (kafka.log.ProducerStateManager)
[2019-02-18 20:35:13,291] INFO [Log partition=msg-topic-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 30 in 78 ms (kafka.log.Log)
[2019-02-18 20:35:13,312] WARN [Log partition=msg-topic-1, dir=D:\tmp\kafka-logs] Found a corrupted index file corresponding to log file D:\tmp\kafka-logs\msg-topic-1\00000000000000000000.log due to Corrupt time index found, time index file (D:\tmp\kafka-logs\msg-topic-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1550487113074}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-02-18 20:35:13,312] INFO [Log partition=msg-topic-1, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:13,325] INFO [ProducerStateManager partition=msg-topic-1] Writing producer snapshot at offset 96 (kafka.log.ProducerStateManager)
[2019-02-18 20:35:13,327] INFO [Log partition=msg-topic-1, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-02-18 20:35:13,327] INFO [Log partition=msg-topic-1, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:13,343] INFO [ProducerStateManager partition=msg-topic-1] Writing producer snapshot at offset 96 (kafka.log.ProducerStateManager)
[2019-02-18 20:35:13,381] INFO [Log partition=msg-topic-1, dir=D:\tmp\kafka-logs] Loading producer state till offset 96 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:13,383] INFO [ProducerStateManager partition=msg-topic-1] Loading producer state from snapshot file 'D:\tmp\kafka-logs\msg-topic-1\00000000000000000096.snapshot' (kafka.log.ProducerStateManager)
[2019-02-18 20:35:13,384] INFO [Log partition=msg-topic-1, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 96 in 87 ms (kafka.log.Log)
[2019-02-18 20:35:13,427] WARN [Log partition=msg-topic-2, dir=D:\tmp\kafka-logs] Found a corrupted index file corresponding to log file D:\tmp\kafka-logs\msg-topic-2\00000000000000000000.log due to Corrupt time index found, time index file (D:\tmp\kafka-logs\msg-topic-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1550487113074}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-02-18 20:35:13,428] INFO [Log partition=msg-topic-2, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:13,449] INFO [ProducerStateManager partition=msg-topic-2] Writing producer snapshot at offset 146 (kafka.log.ProducerStateManager)
[2019-02-18 20:35:13,452] INFO [Log partition=msg-topic-2, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-02-18 20:35:13,453] INFO [Log partition=msg-topic-2, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:13,495] INFO [ProducerStateManager partition=msg-topic-2] Writing producer snapshot at offset 146 (kafka.log.ProducerStateManager)
[2019-02-18 20:35:13,532] INFO [Log partition=msg-topic-2, dir=D:\tmp\kafka-logs] Loading producer state till offset 146 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:13,534] INFO [ProducerStateManager partition=msg-topic-2] Loading producer state from snapshot file 'D:\tmp\kafka-logs\msg-topic-2\00000000000000000146.snapshot' (kafka.log.ProducerStateManager)
[2019-02-18 20:35:13,535] INFO [Log partition=msg-topic-2, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 146 in 142 ms (kafka.log.Log)
[2019-02-18 20:35:13,569] INFO [Log partition=test-topic-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-02-18 20:35:13,570] INFO [Log partition=test-topic-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:13,582] INFO [ProducerStateManager partition=test-topic-0] Writing producer snapshot at offset 14 (kafka.log.ProducerStateManager)
[2019-02-18 20:35:13,616] INFO [Log partition=test-topic-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 14 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:13,618] INFO [ProducerStateManager partition=test-topic-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\test-topic-0\00000000000000000014.snapshot' (kafka.log.ProducerStateManager)
[2019-02-18 20:35:13,618] INFO [Log partition=test-topic-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 14 in 75 ms (kafka.log.Log)
[2019-02-18 20:35:13,645] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-02-18 20:35:13,646] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:13,700] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:13,702] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 76 ms (kafka.log.Log)
[2019-02-18 20:35:13,733] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-02-18 20:35:13,733] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:13,780] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:13,781] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 68 ms (kafka.log.Log)
[2019-02-18 20:35:13,800] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-02-18 20:35:13,801] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:13,866] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:13,868] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 81 ms (kafka.log.Log)
[2019-02-18 20:35:13,895] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-02-18 20:35:13,896] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:13,948] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:13,950] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 74 ms (kafka.log.Log)
[2019-02-18 20:35:13,973] WARN [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Found a corrupted index file corresponding to log file D:\tmp\kafka-logs\__consumer_offsets-12\00000000000000000000.log due to Corrupt time index found, time index file (D:\tmp\kafka-logs\__consumer_offsets-12\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1550481150032}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-02-18 20:35:13,974] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:14,029] INFO [ProducerStateManager partition=__consumer_offsets-12] Writing producer snapshot at offset 2469 (kafka.log.ProducerStateManager)
[2019-02-18 20:35:14,032] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-02-18 20:35:14,033] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:14,080] INFO [ProducerStateManager partition=__consumer_offsets-12] Writing producer snapshot at offset 2469 (kafka.log.ProducerStateManager)
[2019-02-18 20:35:14,122] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Loading producer state till offset 2469 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:14,123] INFO [ProducerStateManager partition=__consumer_offsets-12] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-12\00000000000000002469.snapshot' (kafka.log.ProducerStateManager)
[2019-02-18 20:35:14,123] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2469 in 165 ms (kafka.log.Log)
[2019-02-18 20:35:14,137] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-02-18 20:35:14,137] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:14,173] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:14,173] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 46 ms (kafka.log.Log)
[2019-02-18 20:35:14,194] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-02-18 20:35:14,195] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:14,239] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:14,241] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 63 ms (kafka.log.Log)
[2019-02-18 20:35:14,267] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-02-18 20:35:14,268] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:14,307] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:14,308] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 60 ms (kafka.log.Log)
[2019-02-18 20:35:14,336] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-02-18 20:35:14,336] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:14,390] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:14,392] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 76 ms (kafka.log.Log)
[2019-02-18 20:35:14,419] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-02-18 20:35:14,420] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:14,456] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:14,458] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 59 ms (kafka.log.Log)
[2019-02-18 20:35:14,485] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-02-18 20:35:14,486] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:14,531] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:14,532] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 67 ms (kafka.log.Log)
[2019-02-18 20:35:14,550] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-02-18 20:35:14,550] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:14,689] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:14,691] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 154 ms (kafka.log.Log)
[2019-02-18 20:35:14,718] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-02-18 20:35:14,718] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:14,897] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:14,899] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 201 ms (kafka.log.Log)
[2019-02-18 20:35:14,925] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-02-18 20:35:14,926] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:14,981] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:14,983] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 77 ms (kafka.log.Log)
[2019-02-18 20:35:15,009] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-02-18 20:35:15,010] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:15,056] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:15,058] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 68 ms (kafka.log.Log)
[2019-02-18 20:35:15,083] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-02-18 20:35:15,084] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:15,122] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:15,123] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 58 ms (kafka.log.Log)
[2019-02-18 20:35:15,141] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-02-18 20:35:15,141] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:15,206] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:15,208] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 80 ms (kafka.log.Log)
[2019-02-18 20:35:15,232] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-02-18 20:35:15,233] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:15,272] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:15,273] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 58 ms (kafka.log.Log)
[2019-02-18 20:35:15,288] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-02-18 20:35:15,289] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:15,322] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:15,324] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 47 ms (kafka.log.Log)
[2019-02-18 20:35:15,351] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-02-18 20:35:15,351] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:15,398] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:15,400] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 69 ms (kafka.log.Log)
[2019-02-18 20:35:15,420] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-02-18 20:35:15,421] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:15,464] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:15,465] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 58 ms (kafka.log.Log)
[2019-02-18 20:35:15,480] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-02-18 20:35:15,481] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:15,522] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:15,523] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 54 ms (kafka.log.Log)
[2019-02-18 20:35:15,536] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-02-18 20:35:15,537] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:15,572] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:15,574] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 47 ms (kafka.log.Log)
[2019-02-18 20:35:15,588] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-02-18 20:35:15,589] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:15,624] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:15,625] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 47 ms (kafka.log.Log)
[2019-02-18 20:35:15,646] WARN [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Found a corrupted index file corresponding to log file D:\tmp\kafka-logs\__consumer_offsets-30\00000000000000000000.log due to Corrupt time index found, time index file (D:\tmp\kafka-logs\__consumer_offsets-30\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1550482111786}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-02-18 20:35:15,647] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:15,659] INFO [ProducerStateManager partition=__consumer_offsets-30] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-02-18 20:35:15,661] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-02-18 20:35:15,661] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:15,678] INFO [ProducerStateManager partition=__consumer_offsets-30] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-02-18 20:35:15,706] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:15,706] INFO [ProducerStateManager partition=__consumer_offsets-30] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-30\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-02-18 20:35:15,707] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 79 ms (kafka.log.Log)
[2019-02-18 20:35:15,722] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-02-18 20:35:15,723] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:15,765] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:15,766] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 54 ms (kafka.log.Log)
[2019-02-18 20:35:15,786] WARN [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Found a corrupted index file corresponding to log file D:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000000.log due to Corrupt time index found, time index file (D:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1550471589510}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-02-18 20:35:15,786] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:15,798] INFO [ProducerStateManager partition=__consumer_offsets-32] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-02-18 20:35:15,799] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-02-18 20:35:15,800] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:15,814] INFO [ProducerStateManager partition=__consumer_offsets-32] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-02-18 20:35:15,847] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:15,848] INFO [ProducerStateManager partition=__consumer_offsets-32] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-02-18 20:35:15,848] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 78 ms (kafka.log.Log)
[2019-02-18 20:35:15,864] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-02-18 20:35:15,865] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:15,899] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:15,900] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 47 ms (kafka.log.Log)
[2019-02-18 20:35:15,914] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-02-18 20:35:15,914] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:16,000] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:16,001] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 98 ms (kafka.log.Log)
[2019-02-18 20:35:16,026] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-02-18 20:35:16,026] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:16,082] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:16,084] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 78 ms (kafka.log.Log)
[2019-02-18 20:35:16,109] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-02-18 20:35:16,109] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:16,165] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:16,167] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 78 ms (kafka.log.Log)
[2019-02-18 20:35:16,193] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-02-18 20:35:16,193] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:16,239] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:16,240] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 68 ms (kafka.log.Log)
[2019-02-18 20:35:16,254] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-02-18 20:35:16,255] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:16,297] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:16,298] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 54 ms (kafka.log.Log)
[2019-02-18 20:35:16,313] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-02-18 20:35:16,314] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:16,348] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:16,349] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 47 ms (kafka.log.Log)
[2019-02-18 20:35:16,364] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-02-18 20:35:16,364] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:16,397] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:16,398] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 46 ms (kafka.log.Log)
[2019-02-18 20:35:16,414] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-02-18 20:35:16,414] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:16,505] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:16,506] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 105 ms (kafka.log.Log)
[2019-02-18 20:35:16,521] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-02-18 20:35:16,521] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:16,556] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:16,557] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 46 ms (kafka.log.Log)
[2019-02-18 20:35:16,572] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-02-18 20:35:16,573] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:16,614] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:16,615] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 53 ms (kafka.log.Log)
[2019-02-18 20:35:16,629] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-02-18 20:35:16,629] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:16,664] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:16,665] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 47 ms (kafka.log.Log)
[2019-02-18 20:35:16,677] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-02-18 20:35:16,678] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:16,714] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:16,715] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 47 ms (kafka.log.Log)
[2019-02-18 20:35:16,728] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-02-18 20:35:16,729] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:16,765] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:16,767] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 49 ms (kafka.log.Log)
[2019-02-18 20:35:16,792] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-02-18 20:35:16,792] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:16,841] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:16,843] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 70 ms (kafka.log.Log)
[2019-02-18 20:35:16,873] WARN [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Found a corrupted index file corresponding to log file D:\tmp\kafka-logs\__consumer_offsets-47\00000000000000000000.log due to Corrupt time index found, time index file (D:\tmp\kafka-logs\__consumer_offsets-47\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1550473111790}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-02-18 20:35:16,874] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:16,894] INFO [ProducerStateManager partition=__consumer_offsets-47] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-02-18 20:35:16,897] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-02-18 20:35:16,897] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:16,917] INFO [ProducerStateManager partition=__consumer_offsets-47] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-02-18 20:35:16,956] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:16,956] INFO [ProducerStateManager partition=__consumer_offsets-47] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-47\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-02-18 20:35:16,957] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 108 ms (kafka.log.Log)
[2019-02-18 20:35:16,971] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-02-18 20:35:16,972] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:17,007] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:17,008] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 47 ms (kafka.log.Log)
[2019-02-18 20:35:17,021] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-02-18 20:35:17,021] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:17,056] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:17,057] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 45 ms (kafka.log.Log)
[2019-02-18 20:35:17,078] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-02-18 20:35:17,079] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:17,124] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:17,126] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 65 ms (kafka.log.Log)
[2019-02-18 20:35:17,151] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-02-18 20:35:17,151] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:17,190] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:17,191] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 60 ms (kafka.log.Log)
[2019-02-18 20:35:17,206] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-02-18 20:35:17,207] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:17,249] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:17,250] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 55 ms (kafka.log.Log)
[2019-02-18 20:35:17,275] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-02-18 20:35:17,275] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:17,349] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:17,351] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 95 ms (kafka.log.Log)
[2019-02-18 20:35:17,373] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-02-18 20:35:17,374] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:17,423] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 20:35:17,425] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 70 ms (kafka.log.Log)
[2019-02-18 20:35:17,432] INFO Logs loading complete in 4818 ms. (kafka.log.LogManager)
[2019-02-18 20:35:17,452] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-02-18 20:35:17,454] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-02-18 20:35:17,788] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-02-18 20:35:17,830] INFO [SocketServer brokerId=0] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-02-18 20:35:17,860] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-02-18 20:35:17,861] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-02-18 20:35:17,862] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-02-18 20:35:17,875] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-02-18 20:35:22,476] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-02-18 20:35:22,500] INFO Result of znode creation at /brokers/ids/0 is: OK (kafka.zk.KafkaZkClient)
[2019-02-18 20:35:22,502] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(DESKTOP-6IV0LP1,9092,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-02-18 20:35:22,551] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-02-18 20:35:22,562] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-02-18 20:35:22,562] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-02-18 20:35:22,613] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-02-18 20:35:22,615] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-02-18 20:35:22,620] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:22,650] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:2000,blockEndProducerId:2999) by writing to Zk with path version 3 (kafka.coordinator.transaction.ProducerIdManager)
[2019-02-18 20:35:22,689] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-02-18 20:35:22,691] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-02-18 20:35:22,692] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-02-18 20:35:22,734] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-02-18 20:35:22,756] INFO [SocketServer brokerId=0] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-02-18 20:35:22,766] INFO Kafka version : 2.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-02-18 20:35:22,769] INFO Kafka commitId : 809be928f1ae004e (org.apache.kafka.common.utils.AppInfoParser)
[2019-02-18 20:35:22,780] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2019-02-18 20:35:22,810] INFO Got user-level KeeperException when processing sessionid:0x1000573f3780000 type:multi cxid:0x70 zxid:0xca txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/reassign_partitions Error:KeeperErrorCode = NoNode for /admin/reassign_partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-18 20:35:22,839] INFO Got user-level KeeperException when processing sessionid:0x1000573f3780000 type:multi cxid:0x72 zxid:0xcb txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-18 20:35:22,905] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, msg-topic-2, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, first-topic-1, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, first-topic-0, test-topic-0, msg-topic-0, msg-topic-1, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-02-18 20:35:22,931] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-18 20:35:22,935] INFO [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-18 20:35:22,977] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-18 20:35:22,978] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-18 20:35:23,004] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-18 20:35:23,004] INFO [Partition __consumer_offsets-48 broker=0] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-18 20:35:23,039] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-18 20:35:23,042] INFO [Partition __consumer_offsets-10 broker=0] __consumer_offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-18 20:35:23,074] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-18 20:35:23,074] INFO [Partition __consumer_offsets-45 broker=0] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-18 20:35:23,106] INFO Replica loaded for partition first-topic-1 with initial high watermark 155 (kafka.cluster.Replica)
[2019-02-18 20:35:23,106] INFO [Partition first-topic-1 broker=0] first-topic-1 starts at Leader Epoch 0 from offset 155. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-18 20:35:23,112] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-18 20:35:23,113] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-18 20:35:23,147] INFO Replica loaded for partition msg-topic-2 with initial high watermark 146 (kafka.cluster.Replica)
[2019-02-18 20:35:23,148] INFO [Partition msg-topic-2 broker=0] msg-topic-2 starts at Leader Epoch 0 from offset 146. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-18 20:35:23,154] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-18 20:35:23,155] INFO [Partition __consumer_offsets-7 broker=0] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-18 20:35:23,189] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-18 20:35:23,189] INFO [Partition __consumer_offsets-42 broker=0] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-18 20:35:23,223] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-18 20:35:23,225] INFO [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-18 20:35:23,255] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-18 20:35:23,256] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-18 20:35:23,294] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-18 20:35:23,294] INFO [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-18 20:35:23,327] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-18 20:35:23,328] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-18 20:35:23,356] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-18 20:35:23,356] INFO [Partition __consumer_offsets-39 broker=0] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-18 20:35:23,390] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-18 20:35:23,390] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-18 20:35:23,422] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-18 20:35:23,422] INFO [Partition __consumer_offsets-36 broker=0] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-18 20:35:23,453] INFO Replica loaded for partition test-topic-0 with initial high watermark 14 (kafka.cluster.Replica)
[2019-02-18 20:35:23,453] INFO [Partition test-topic-0 broker=0] test-topic-0 starts at Leader Epoch 0 from offset 14. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-18 20:35:23,457] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-18 20:35:23,457] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-18 20:35:23,487] INFO Replica loaded for partition msg-topic-0 with initial high watermark 30 (kafka.cluster.Replica)
[2019-02-18 20:35:23,487] INFO [Partition msg-topic-0 broker=0] msg-topic-0 starts at Leader Epoch 0 from offset 30. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-18 20:35:23,491] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-18 20:35:23,493] INFO [Partition __consumer_offsets-33 broker=0] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-18 20:35:23,544] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-18 20:35:23,545] INFO [Partition __consumer_offsets-49 broker=0] __consumer_offsets-49 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-18 20:35:23,571] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-18 20:35:23,571] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-18 20:35:23,603] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 3 (kafka.cluster.Replica)
[2019-02-18 20:35:23,604] INFO [Partition __consumer_offsets-30 broker=0] __consumer_offsets-30 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-18 20:35:23,607] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-18 20:35:23,607] INFO [Partition __consumer_offsets-46 broker=0] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-18 20:35:23,680] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-18 20:35:23,681] INFO [Partition __consumer_offsets-27 broker=0] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-18 20:35:23,714] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-18 20:35:23,716] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-18 20:35:23,747] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-18 20:35:23,748] INFO [Partition __consumer_offsets-24 broker=0] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-18 20:35:23,778] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-18 20:35:23,778] INFO [Partition __consumer_offsets-43 broker=0] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-18 20:35:23,822] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-18 20:35:23,823] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-18 20:35:23,856] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-18 20:35:23,856] INFO [Partition __consumer_offsets-21 broker=0] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-18 20:35:23,897] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-18 20:35:23,897] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-18 20:35:23,947] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-18 20:35:23,947] INFO [Partition __consumer_offsets-40 broker=0] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-18 20:35:23,980] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-18 20:35:23,980] INFO [Partition __consumer_offsets-37 broker=0] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-18 20:35:24,013] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-18 20:35:24,014] INFO [Partition __consumer_offsets-18 broker=0] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-18 20:35:24,072] INFO Replica loaded for partition msg-topic-1 with initial high watermark 96 (kafka.cluster.Replica)
[2019-02-18 20:35:24,073] INFO [Partition msg-topic-1 broker=0] msg-topic-1 starts at Leader Epoch 0 from offset 96. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-18 20:35:24,078] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-18 20:35:24,078] INFO [Partition __consumer_offsets-34 broker=0] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-18 20:35:24,113] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-18 20:35:24,114] INFO [Partition __consumer_offsets-15 broker=0] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-18 20:35:24,199] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 2469 (kafka.cluster.Replica)
[2019-02-18 20:35:24,200] INFO [Partition __consumer_offsets-12 broker=0] __consumer_offsets-12 starts at Leader Epoch 0 from offset 2469. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-18 20:35:24,211] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-18 20:35:24,212] INFO [Partition __consumer_offsets-31 broker=0] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-18 20:35:24,247] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-18 20:35:24,247] INFO [Partition __consumer_offsets-9 broker=0] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-18 20:35:24,281] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 3 (kafka.cluster.Replica)
[2019-02-18 20:35:24,281] INFO [Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-18 20:35:24,286] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-18 20:35:24,287] INFO [Partition __consumer_offsets-19 broker=0] __consumer_offsets-19 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-18 20:35:24,347] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-18 20:35:24,347] INFO [Partition __consumer_offsets-28 broker=0] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-18 20:35:24,381] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-18 20:35:24,381] INFO [Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-18 20:35:24,413] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-18 20:35:24,414] INFO [Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-18 20:35:24,472] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-18 20:35:24,472] INFO [Partition __consumer_offsets-6 broker=0] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-18 20:35:24,506] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-18 20:35:24,507] INFO [Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-18 20:35:24,539] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-18 20:35:24,539] INFO [Partition __consumer_offsets-25 broker=0] __consumer_offsets-25 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-18 20:35:24,572] INFO Replica loaded for partition first-topic-0 with initial high watermark 514 (kafka.cluster.Replica)
[2019-02-18 20:35:24,573] INFO [Partition first-topic-0 broker=0] first-topic-0 starts at Leader Epoch 0 from offset 514. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-18 20:35:24,579] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-18 20:35:24,580] INFO [Partition __consumer_offsets-16 broker=0] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-18 20:35:24,620] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-18 20:35:24,620] INFO [Partition __consumer_offsets-22 broker=0] __consumer_offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-18 20:35:24,656] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-18 20:35:24,657] INFO [Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-18 20:35:24,690] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 3 (kafka.cluster.Replica)
[2019-02-18 20:35:24,691] INFO [Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-18 20:35:24,697] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-18 20:35:24,697] INFO [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-18 20:35:24,730] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-18 20:35:24,731] INFO [Partition __consumer_offsets-13 broker=0] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-18 20:35:24,772] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,773] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,774] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,776] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,776] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,776] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,777] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,777] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,777] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,778] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,778] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,778] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,779] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,779] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,779] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,780] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,780] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,781] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,781] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,782] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,785] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,785] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,786] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,786] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,787] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,787] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,787] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,788] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,788] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,788] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,789] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,789] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,789] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,790] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,790] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,791] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,791] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,791] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,792] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,792] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,792] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,793] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,793] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,793] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,794] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,796] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,797] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,798] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,798] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,799] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,810] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 37 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,810] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,811] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,812] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,812] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,813] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,813] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,814] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,816] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,819] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,820] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,821] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,859] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 38 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,860] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,861] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,861] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,863] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,863] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,864] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,864] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,864] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,865] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,865] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,865] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,866] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,866] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,866] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,866] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,867] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,867] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,873] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,874] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,877] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,878] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,878] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,878] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,879] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,946] INFO [GroupCoordinator 0]: Loading group metadata for test-group with generation 26 (kafka.coordinator.group.GroupCoordinator)
[2019-02-18 20:35:24,947] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 68 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,948] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,950] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,950] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,951] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,953] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,955] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,955] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,958] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,958] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,959] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,959] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:35:24,960] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:45:22,625] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 9 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 20:55:22,616] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 21:05:22,615] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 21:15:22,615] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 21:25:22,615] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 21:35:22,615] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 21:45:22,615] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 21:55:22,615] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 22:05:22,615] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 22:10:12,263] INFO Accepted socket connection from /127.0.0.1:55587 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-02-18 22:10:12,267] INFO Client attempting to establish new session at /127.0.0.1:55587 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-02-18 22:10:12,277] INFO Established session 0x1000573f3780001 with negotiated timeout 30000 for client /127.0.0.1:55587 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-02-18 22:10:12,546] INFO Got user-level KeeperException when processing sessionid:0x1000573f3780001 type:setData cxid:0x4 zxid:0xcd txntype:-1 reqpath:n/a Error Path:/config/topics/emp-topic Error:KeeperErrorCode = NoNode for /config/topics/emp-topic (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-18 22:10:12,628] INFO Processed session termination for sessionid: 0x1000573f3780001 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-18 22:10:12,642] INFO Closed socket connection for client /127.0.0.1:55587 which had sessionid 0x1000573f3780001 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-02-18 22:10:12,716] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(emp-topic-1, emp-topic-0) (kafka.server.ReplicaFetcherManager)
[2019-02-18 22:10:12,725] INFO [Log partition=emp-topic-1, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 22:10:12,726] INFO [Log partition=emp-topic-1, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-02-18 22:10:12,729] INFO Created log for partition emp-topic-1 in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-18 22:10:12,732] INFO [Partition emp-topic-1 broker=0] No checkpointed highwatermark is found for partition emp-topic-1 (kafka.cluster.Partition)
[2019-02-18 22:10:12,733] INFO Replica loaded for partition emp-topic-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-18 22:10:12,734] INFO [Partition emp-topic-1 broker=0] emp-topic-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-18 22:10:12,778] INFO [Log partition=emp-topic-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-18 22:10:12,779] INFO [Log partition=emp-topic-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2019-02-18 22:10:12,780] INFO Created log for partition emp-topic-0 in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-18 22:10:12,782] INFO [Partition emp-topic-0 broker=0] No checkpointed highwatermark is found for partition emp-topic-0 (kafka.cluster.Partition)
[2019-02-18 22:10:12,782] INFO Replica loaded for partition emp-topic-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-18 22:10:12,783] INFO [Partition emp-topic-0 broker=0] emp-topic-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-18 22:14:29,032] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-45757 in state PreparingRebalance with old generation 0 (__consumer_offsets-19) (reason: Adding new member consumer-1-59520989-f04f-4d65-bc60-c05ae2646896) (kafka.coordinator.group.GroupCoordinator)
[2019-02-18 22:14:29,038] INFO [GroupCoordinator 0]: Stabilized group console-consumer-45757 generation 1 (__consumer_offsets-19) (kafka.coordinator.group.GroupCoordinator)
[2019-02-18 22:14:29,048] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-45757 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-02-18 22:15:22,615] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 22:17:28,338] INFO [GroupCoordinator 0]: Preparing to rebalance group test-group in state PreparingRebalance with old generation 26 (__consumer_offsets-12) (reason: Adding new member consumer-1-9637c4e4-9f50-4ef7-a1c5-740477991445) (kafka.coordinator.group.GroupCoordinator)
[2019-02-18 22:17:28,339] INFO [GroupCoordinator 0]: Stabilized group test-group generation 27 (__consumer_offsets-12) (kafka.coordinator.group.GroupCoordinator)
[2019-02-18 22:17:28,343] INFO [GroupCoordinator 0]: Assignment received from leader for group test-group for generation 27 (kafka.coordinator.group.GroupCoordinator)
[2019-02-18 22:18:56,124] INFO [GroupCoordinator 0]: Preparing to rebalance group test-group in state PreparingRebalance with old generation 27 (__consumer_offsets-12) (reason: Adding new member consumer-1-94ac425a-0d35-40ad-99a6-a2c30bf5ee1b) (kafka.coordinator.group.GroupCoordinator)
[2019-02-18 22:18:58,373] INFO [GroupCoordinator 0]: Stabilized group test-group generation 28 (__consumer_offsets-12) (kafka.coordinator.group.GroupCoordinator)
[2019-02-18 22:18:58,378] INFO [GroupCoordinator 0]: Assignment received from leader for group test-group for generation 28 (kafka.coordinator.group.GroupCoordinator)
[2019-02-18 22:19:32,388] INFO [GroupCoordinator 0]: Member consumer-1-9637c4e4-9f50-4ef7-a1c5-740477991445 in group test-group has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-02-18 22:19:32,391] INFO [GroupCoordinator 0]: Preparing to rebalance group test-group in state PreparingRebalance with old generation 28 (__consumer_offsets-12) (reason: removing member consumer-1-9637c4e4-9f50-4ef7-a1c5-740477991445 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-02-18 22:19:33,393] INFO [GroupCoordinator 0]: Member consumer-1-94ac425a-0d35-40ad-99a6-a2c30bf5ee1b in group test-group has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-02-18 22:19:33,394] INFO [GroupCoordinator 0]: Group test-group with generation 29 is now empty (__consumer_offsets-12) (kafka.coordinator.group.GroupCoordinator)
[2019-02-18 22:19:48,164] INFO [GroupCoordinator 0]: Preparing to rebalance group test-group in state PreparingRebalance with old generation 29 (__consumer_offsets-12) (reason: Adding new member consumer-1-52aa037f-a89d-444d-862d-f28b206d24a9) (kafka.coordinator.group.GroupCoordinator)
[2019-02-18 22:19:48,165] INFO [GroupCoordinator 0]: Stabilized group test-group generation 30 (__consumer_offsets-12) (kafka.coordinator.group.GroupCoordinator)
[2019-02-18 22:19:48,169] INFO [GroupCoordinator 0]: Assignment received from leader for group test-group for generation 30 (kafka.coordinator.group.GroupCoordinator)
[2019-02-18 22:25:22,615] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 22:35:22,615] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 22:45:22,615] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 22:46:58,378] INFO [GroupCoordinator 0]: Member consumer-1-52aa037f-a89d-444d-862d-f28b206d24a9 in group test-group has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-02-18 22:46:58,378] INFO [GroupCoordinator 0]: Preparing to rebalance group test-group in state PreparingRebalance with old generation 30 (__consumer_offsets-12) (reason: removing member consumer-1-52aa037f-a89d-444d-862d-f28b206d24a9 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-02-18 22:46:58,380] INFO [GroupCoordinator 0]: Group test-group with generation 31 is now empty (__consumer_offsets-12) (kafka.coordinator.group.GroupCoordinator)
[2019-02-18 22:55:22,617] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 23:05:22,616] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 23:15:22,615] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 23:25:22,616] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 23:35:22,617] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 23:45:22,615] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-18 23:55:22,615] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 00:05:22,616] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 00:15:22,617] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 00:25:22,616] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 00:35:22,615] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 00:45:22,615] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 00:55:22,616] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 00:55:50,848] INFO [GroupCoordinator 0]: Preparing to rebalance group test-group in state PreparingRebalance with old generation 31 (__consumer_offsets-12) (reason: Adding new member consumer-1-4f73cd6e-6bd9-47d9-9399-e47c68a6d59f) (kafka.coordinator.group.GroupCoordinator)
[2019-02-19 00:55:50,849] INFO [GroupCoordinator 0]: Stabilized group test-group generation 32 (__consumer_offsets-12) (kafka.coordinator.group.GroupCoordinator)
[2019-02-19 00:55:50,853] INFO [GroupCoordinator 0]: Assignment received from leader for group test-group for generation 32 (kafka.coordinator.group.GroupCoordinator)
[2019-02-19 00:59:38,173] INFO [GroupCoordinator 0]: Preparing to rebalance group test-group in state PreparingRebalance with old generation 32 (__consumer_offsets-12) (reason: Adding new member consumer-1-8d1fe259-52aa-4f94-acbb-8fe54db2cdcb) (kafka.coordinator.group.GroupCoordinator)
[2019-02-19 00:59:38,902] INFO [GroupCoordinator 0]: Stabilized group test-group generation 33 (__consumer_offsets-12) (kafka.coordinator.group.GroupCoordinator)
[2019-02-19 00:59:38,907] INFO [GroupCoordinator 0]: Assignment received from leader for group test-group for generation 33 (kafka.coordinator.group.GroupCoordinator)
[2019-02-19 01:00:06,846] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-45757 in state PreparingRebalance with old generation 1 (__consumer_offsets-19) (reason: removing member consumer-1-59520989-f04f-4d65-bc60-c05ae2646896 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-02-19 01:00:06,850] INFO [GroupCoordinator 0]: Group console-consumer-45757 with generation 2 is now empty (__consumer_offsets-19) (kafka.coordinator.group.GroupCoordinator)
[2019-02-19 01:02:11,441] INFO Got user-level KeeperException when processing sessionid:0x1000573f3780000 type:setData cxid:0xbb zxid:0xd6 txntype:-1 reqpath:n/a Error Path:/config/topics/empjson-topic Error:KeeperErrorCode = NoNode for /config/topics/empjson-topic (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-19 01:02:11,469] INFO Topic creation Map(empjson-topic-0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2019-02-19 01:02:11,498] INFO [KafkaApi-0] Auto creation of topic empjson-topic with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2019-02-19 01:02:11,517] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-75421 in state PreparingRebalance with old generation 0 (__consumer_offsets-0) (reason: Adding new member consumer-1-91080384-604e-4238-84ce-e3df94e72fdc) (kafka.coordinator.group.GroupCoordinator)
[2019-02-19 01:02:11,517] INFO [GroupCoordinator 0]: Stabilized group console-consumer-75421 generation 1 (__consumer_offsets-0) (kafka.coordinator.group.GroupCoordinator)
[2019-02-19 01:02:11,542] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(empjson-topic-0) (kafka.server.ReplicaFetcherManager)
[2019-02-19 01:02:11,545] INFO [Log partition=empjson-topic-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 01:02:11,546] INFO [Log partition=empjson-topic-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2019-02-19 01:02:11,547] INFO Created log for partition empjson-topic-0 in D:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 01:02:11,548] INFO [Partition empjson-topic-0 broker=0] No checkpointed highwatermark is found for partition empjson-topic-0 (kafka.cluster.Partition)
[2019-02-19 01:02:11,548] INFO Replica loaded for partition empjson-topic-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 01:02:11,548] INFO [Partition empjson-topic-0 broker=0] empjson-topic-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 01:02:11,609] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-75421 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-02-19 01:02:13,929] INFO [GroupCoordinator 0]: Member consumer-1-8d1fe259-52aa-4f94-acbb-8fe54db2cdcb in group test-group has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-02-19 01:02:13,929] INFO [GroupCoordinator 0]: Preparing to rebalance group test-group in state PreparingRebalance with old generation 33 (__consumer_offsets-12) (reason: removing member consumer-1-8d1fe259-52aa-4f94-acbb-8fe54db2cdcb on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-02-19 01:02:14,928] INFO [GroupCoordinator 0]: Stabilized group test-group generation 34 (__consumer_offsets-12) (kafka.coordinator.group.GroupCoordinator)
[2019-02-19 01:02:14,930] INFO [GroupCoordinator 0]: Assignment received from leader for group test-group for generation 34 (kafka.coordinator.group.GroupCoordinator)
[2019-02-19 01:03:59,099] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-75421 in state PreparingRebalance with old generation 1 (__consumer_offsets-0) (reason: removing member consumer-1-91080384-604e-4238-84ce-e3df94e72fdc on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-02-19 01:03:59,100] INFO [GroupCoordinator 0]: Group console-consumer-75421 with generation 2 is now empty (__consumer_offsets-0) (kafka.coordinator.group.GroupCoordinator)
[2019-02-19 01:05:22,616] INFO [GroupMetadataManager brokerId=0] Group console-consumer-75421 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:05:22,619] INFO [GroupMetadataManager brokerId=0] Group console-consumer-45757 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:05:22,619] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:06:21,887] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-57568 in state PreparingRebalance with old generation 0 (__consumer_offsets-32) (reason: Adding new member consumer-1-d9bbd75a-3298-4f2c-b0fb-0a4057e88e6f) (kafka.coordinator.group.GroupCoordinator)
[2019-02-19 01:06:21,888] INFO [GroupCoordinator 0]: Stabilized group console-consumer-57568 generation 1 (__consumer_offsets-32) (kafka.coordinator.group.GroupCoordinator)
[2019-02-19 01:06:21,892] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-57568 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-02-19 01:07:19,673] ERROR Error while reading checkpoint file D:\tmp\kafka-logs\cleaner-offset-checkpoint (kafka.server.LogDirFailureChannel)
java.nio.file.NoSuchFileException: D:\tmp\kafka-logs\cleaner-offset-checkpoint
	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:79)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.newByteChannel(WindowsFileSystemProvider.java:230)
	at java.nio.file.Files.newByteChannel(Files.java:361)
	at java.nio.file.Files.newByteChannel(Files.java:407)
	at java.nio.file.spi.FileSystemProvider.newInputStream(FileSystemProvider.java:384)
	at java.nio.file.Files.newInputStream(Files.java:152)
	at java.nio.file.Files.newBufferedReader(Files.java:2784)
	at java.nio.file.Files.newBufferedReader(Files.java:2816)
	at kafka.server.checkpoints.CheckpointFile.liftedTree2$1(CheckpointFile.scala:87)
	at kafka.server.checkpoints.CheckpointFile.read(CheckpointFile.scala:86)
	at kafka.server.checkpoints.OffsetCheckpointFile.read(OffsetCheckpointFile.scala:61)
	at kafka.log.LogCleanerManager.$anonfun$allCleanerCheckpoints$2(LogCleanerManager.scala:140)
	at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:240)
	at scala.collection.Iterator.foreach(Iterator.scala:937)
	at scala.collection.Iterator.foreach$(Iterator.scala:937)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1425)
	at scala.collection.MapLike$DefaultValuesIterable.foreach(MapLike.scala:209)
	at scala.collection.TraversableLike.flatMap(TraversableLike.scala:240)
	at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:237)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:104)
	at kafka.log.LogCleanerManager.$anonfun$allCleanerCheckpoints$1(LogCleanerManager.scala:138)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:251)
	at kafka.log.LogCleanerManager.allCleanerCheckpoints(LogCleanerManager.scala:146)
	at kafka.log.LogCleanerManager.$anonfun$grabFilthiestCompactedLog$1(LogCleanerManager.scala:177)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:251)
	at kafka.log.LogCleanerManager.grabFilthiestCompactedLog(LogCleanerManager.scala:174)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:313)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:300)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-02-19 01:07:19,680] INFO [ReplicaManager broker=0] Stopping serving replicas in dir D:\tmp\kafka-logs (kafka.server.ReplicaManager)
[2019-02-19 01:07:19,690] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, msg-topic-2, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, emp-topic-0, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, empjson-topic-0, emp-topic-1, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, first-topic-1, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, first-topic-0, test-topic-0, msg-topic-0, msg-topic-1, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-02-19 01:07:19,692] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, msg-topic-2, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, emp-topic-0, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, empjson-topic-0, emp-topic-1, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, first-topic-1, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, first-topic-0, test-topic-0, msg-topic-0, msg-topic-1, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaAlterLogDirsManager)
[2019-02-19 01:07:19,734] INFO [ReplicaManager broker=0] Broker 0 stopped fetcher for partitions __consumer_offsets-22,msg-topic-2,__consumer_offsets-30,__consumer_offsets-8,__consumer_offsets-21,__consumer_offsets-4,__consumer_offsets-27,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-46,emp-topic-0,__consumer_offsets-25,__consumer_offsets-35,__consumer_offsets-41,__consumer_offsets-33,__consumer_offsets-23,__consumer_offsets-49,empjson-topic-0,emp-topic-1,__consumer_offsets-47,__consumer_offsets-16,__consumer_offsets-28,__consumer_offsets-31,__consumer_offsets-36,__consumer_offsets-42,__consumer_offsets-3,__consumer_offsets-18,__consumer_offsets-37,__consumer_offsets-15,__consumer_offsets-24,__consumer_offsets-38,__consumer_offsets-17,__consumer_offsets-48,first-topic-1,__consumer_offsets-19,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-2,__consumer_offsets-43,__consumer_offsets-6,__consumer_offsets-14,first-topic-0,test-topic-0,msg-topic-0,msg-topic-1,__consumer_offsets-20,__consumer_offsets-0,__consumer_offsets-44,__consumer_offsets-39,__consumer_offsets-12,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5,__consumer_offsets-26,__consumer_offsets-29,__consumer_offsets-34,__consumer_offsets-10,__consumer_offsets-32,__consumer_offsets-40 and stopped moving logs for partitions  because they are in the failed log directory D:\tmp\kafka-logs. (kafka.server.ReplicaManager)
[2019-02-19 01:07:19,735] INFO Stopping serving logs in dir D:\tmp\kafka-logs (kafka.log.LogManager)
[2019-02-19 01:07:19,739] ERROR Shutdown broker because all log dirs in D:\tmp\kafka-logs have failed (kafka.log.LogManager)
[2019-02-19 01:07:20,069] WARN Exception causing close of session 0x1000573f3780000: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2019-02-19 01:07:20,071] INFO Closed socket connection for client /127.0.0.1:55109 which had sessionid 0x1000573f3780000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-02-19 01:07:28,490] INFO Expiring session 0x1000573f3780000, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-02-19 01:07:28,490] INFO Processed session termination for sessionid: 0x1000573f3780000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-19 01:13:24,097] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-02-19 01:13:24,579] INFO starting (kafka.server.KafkaServer)
[2019-02-19 01:13:24,581] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-02-19 01:13:24,598] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-02-19 01:13:29,123] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-02-19 01:13:29,124] INFO Client environment:host.name=DESKTOP-6IV0LP1 (org.apache.zookeeper.ZooKeeper)
[2019-02-19 01:13:29,124] INFO Client environment:java.version=1.8.0_201 (org.apache.zookeeper.ZooKeeper)
[2019-02-19 01:13:29,124] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-02-19 01:13:29,125] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_201\jre (org.apache.zookeeper.ZooKeeper)
[2019-02-19 01:13:29,125] INFO Client environment:java.class.path=D:\Software\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;D:\Software\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;D:\Software\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;D:\Software\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;D:\Software\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;D:\Software\kafka_2.12-2.1.0\libs\compileScala.mapping;D:\Software\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;D:\Software\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\guava-20.0.jar;D:\Software\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;D:\Software\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;D:\Software\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;D:\Software\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;D:\Software\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;D:\Software\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;D:\Software\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;D:\Software\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;D:\Software\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;D:\Software\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;D:\Software\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;D:\Software\kafka_2.12-2.1.0\libs\javax.inject-1.jar;D:\Software\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;D:\Software\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;D:\Software\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;D:\Software\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;D:\Software\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;D:\Software\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;D:\Software\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;D:\Software\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;D:\Software\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;D:\Software\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;D:\Software\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;D:\Software\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;D:\Software\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;D:\Software\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;D:\Software\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;D:\Software\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;D:\Software\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;D:\Software\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;D:\Software\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;D:\Software\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;D:\Software\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;D:\Software\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;D:\Software\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;D:\Software\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;D:\Software\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;D:\Software\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;D:\Software\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;D:\Software\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.ZooKeeper)
[2019-02-19 01:13:29,126] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_201\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;%JAVA_HOME%\bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Users\Administrator\AppData\Local\Microsoft\WindowsApps;;. (org.apache.zookeeper.ZooKeeper)
[2019-02-19 01:13:29,127] INFO Client environment:java.io.tmpdir=C:\Users\ADMINI~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-02-19 01:13:29,128] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-02-19 01:13:29,129] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-02-19 01:13:29,129] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-02-19 01:13:29,130] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-02-19 01:13:29,130] INFO Client environment:user.name=Administrator (org.apache.zookeeper.ZooKeeper)
[2019-02-19 01:13:29,131] INFO Client environment:user.home=C:\Users\Administrator (org.apache.zookeeper.ZooKeeper)
[2019-02-19 01:13:29,131] INFO Client environment:user.dir=D:\Software\kafka_2.12-2.1.0 (org.apache.zookeeper.ZooKeeper)
[2019-02-19 01:13:29,135] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@78b66d36 (org.apache.zookeeper.ZooKeeper)
[2019-02-19 01:13:29,175] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-02-19 01:13:29,176] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-02-19 01:13:29,179] INFO Accepted socket connection from /127.0.0.1:56485 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-02-19 01:13:29,179] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-02-19 01:13:29,184] INFO Client attempting to establish new session at /127.0.0.1:56485 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-02-19 01:13:29,203] INFO Established session 0x1000573f3780002 with negotiated timeout 6000 for client /127.0.0.1:56485 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-02-19 01:13:29,205] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1000573f3780002, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-02-19 01:13:29,209] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-02-19 01:13:29,258] INFO Got user-level KeeperException when processing sessionid:0x1000573f3780002 type:create cxid:0x1 zxid:0xde txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-19 01:13:29,280] INFO Got user-level KeeperException when processing sessionid:0x1000573f3780002 type:create cxid:0x2 zxid:0xdf txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-19 01:13:29,291] INFO Got user-level KeeperException when processing sessionid:0x1000573f3780002 type:create cxid:0x3 zxid:0xe0 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-19 01:13:29,303] INFO Got user-level KeeperException when processing sessionid:0x1000573f3780002 type:create cxid:0x4 zxid:0xe1 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-19 01:13:29,316] INFO Got user-level KeeperException when processing sessionid:0x1000573f3780002 type:create cxid:0x5 zxid:0xe2 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-19 01:13:29,330] INFO Got user-level KeeperException when processing sessionid:0x1000573f3780002 type:create cxid:0x6 zxid:0xe3 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-19 01:13:29,341] INFO Got user-level KeeperException when processing sessionid:0x1000573f3780002 type:create cxid:0x7 zxid:0xe4 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-19 01:13:29,354] INFO Got user-level KeeperException when processing sessionid:0x1000573f3780002 type:create cxid:0x8 zxid:0xe5 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-19 01:13:29,366] INFO Got user-level KeeperException when processing sessionid:0x1000573f3780002 type:create cxid:0x9 zxid:0xe6 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-19 01:13:29,380] INFO Got user-level KeeperException when processing sessionid:0x1000573f3780002 type:create cxid:0xa zxid:0xe7 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-19 01:13:29,391] INFO Got user-level KeeperException when processing sessionid:0x1000573f3780002 type:create cxid:0xb zxid:0xe8 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-19 01:13:29,404] INFO Got user-level KeeperException when processing sessionid:0x1000573f3780002 type:create cxid:0xc zxid:0xe9 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-19 01:13:29,417] INFO Got user-level KeeperException when processing sessionid:0x1000573f3780002 type:create cxid:0xd zxid:0xea txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-19 01:13:29,613] INFO Cluster ID = 5Tl4DeAbRCSXBvJrXLLt7Q (kafka.server.KafkaServer)
[2019-02-19 01:13:29,616] WARN No meta.properties file under dir D:\tmp\kafka-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-02-19 01:13:29,685] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-02-19 01:13:29,696] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-02-19 01:13:29,724] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-02-19 01:13:29,724] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-02-19 01:13:29,726] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-02-19 01:13:29,764] INFO Loading logs. (kafka.log.LogManager)
[2019-02-19 01:13:29,803] WARN [Log partition=emp-topic-0, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\emp-topic-0\00000000000000000000.index, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:29,804] WARN [Log partition=emp-topic-0, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\emp-topic-0\00000000000000000000.timeindex, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:29,829] INFO [Log partition=emp-topic-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 01:13:29,848] INFO [Log partition=emp-topic-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 54 ms (kafka.log.Log)
[2019-02-19 01:13:29,858] WARN [Log partition=emp-topic-1, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\emp-topic-1\00000000000000000000.index, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:29,917] WARN [Log partition=emp-topic-1, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\emp-topic-1\00000000000000000000.timeindex, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:29,977] INFO [Log partition=emp-topic-1, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 01:13:29,979] INFO [Log partition=emp-topic-1, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 122 ms (kafka.log.Log)
[2019-02-19 01:13:29,990] WARN [Log partition=empjson-topic-0, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\empjson-topic-0\00000000000000000000.index, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:29,992] WARN [Log partition=empjson-topic-0, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\empjson-topic-0\00000000000000000000.timeindex, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:29,996] INFO [Log partition=empjson-topic-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 01:13:30,001] INFO [Log partition=empjson-topic-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2019-02-19 01:13:30,006] WARN [Log partition=first-topic-0, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\first-topic-0\00000000000000000000.index, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,007] WARN [Log partition=first-topic-0, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\first-topic-0\00000000000000000000.timeindex, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,011] INFO [Log partition=first-topic-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 01:13:30,012] INFO [Log partition=first-topic-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-02-19 01:13:30,025] WARN [Log partition=first-topic-1, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\first-topic-1\00000000000000000000.index, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,025] WARN [Log partition=first-topic-1, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\first-topic-1\00000000000000000000.timeindex, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,026] INFO [Log partition=first-topic-1, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 01:13:30,027] INFO [Log partition=first-topic-1, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-02-19 01:13:30,033] WARN [Log partition=msg-topic-0, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\msg-topic-0\00000000000000000000.index, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,034] WARN [Log partition=msg-topic-0, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\msg-topic-0\00000000000000000000.timeindex, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,035] INFO [Log partition=msg-topic-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 01:13:30,036] INFO [Log partition=msg-topic-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-02-19 01:13:30,040] WARN [Log partition=msg-topic-1, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\msg-topic-1\00000000000000000000.index, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,041] WARN [Log partition=msg-topic-1, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\msg-topic-1\00000000000000000000.timeindex, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,043] INFO [Log partition=msg-topic-1, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 01:13:30,050] INFO [Log partition=msg-topic-1, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2019-02-19 01:13:30,054] WARN [Log partition=msg-topic-2, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\msg-topic-2\00000000000000000000.index, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,055] WARN [Log partition=msg-topic-2, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\msg-topic-2\00000000000000000000.timeindex, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,057] INFO [Log partition=msg-topic-2, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 01:13:30,058] INFO [Log partition=msg-topic-2, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-02-19 01:13:30,062] WARN [Log partition=test-topic-0, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\test-topic-0\00000000000000000000.index, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,065] WARN [Log partition=test-topic-0, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\test-topic-0\00000000000000000000.timeindex, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,068] INFO [Log partition=test-topic-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 01:13:30,069] INFO [Log partition=test-topic-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2019-02-19 01:13:30,072] WARN [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-0\00000000000000000000.index, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,074] WARN [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-0\00000000000000000000.timeindex, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,076] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 01:13:30,082] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2019-02-19 01:13:30,087] WARN [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-1\00000000000000000000.index, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,087] WARN [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-1\00000000000000000000.timeindex, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,089] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 01:13:30,090] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-02-19 01:13:30,093] WARN [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-10\00000000000000000000.index, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,094] WARN [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-10\00000000000000000000.timeindex, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,101] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 01:13:30,102] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2019-02-19 01:13:30,110] WARN [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-11\00000000000000000000.index, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,111] WARN [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-11\00000000000000000000.timeindex, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,112] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 01:13:30,113] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-02-19 01:13:30,118] WARN [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-12\00000000000000000000.index, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,118] WARN [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-12\00000000000000000000.timeindex, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,120] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 01:13:30,121] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-02-19 01:13:30,125] WARN [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-13\00000000000000000000.index, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,125] WARN [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-13\00000000000000000000.timeindex, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,127] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 01:13:30,134] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2019-02-19 01:13:30,140] WARN [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-14\00000000000000000000.index, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,141] WARN [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-14\00000000000000000000.timeindex, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,143] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 01:13:30,147] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2019-02-19 01:13:30,152] WARN [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-15\00000000000000000000.index, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,152] WARN [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-15\00000000000000000000.timeindex, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,153] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 01:13:30,154] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-02-19 01:13:30,158] WARN [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.index, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,158] WARN [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.timeindex, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,160] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 01:13:30,168] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2019-02-19 01:13:30,174] WARN [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-17\00000000000000000000.index, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,174] WARN [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-17\00000000000000000000.timeindex, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,176] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 01:13:30,177] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-02-19 01:13:30,184] WARN [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000000.index, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,185] WARN [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000000.timeindex, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,186] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 01:13:30,187] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-02-19 01:13:30,190] WARN [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-19\00000000000000000000.index, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,192] WARN [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-19\00000000000000000000.timeindex, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,194] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 01:13:30,199] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2019-02-19 01:13:30,203] WARN [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-2\00000000000000000000.index, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,203] WARN [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-2\00000000000000000000.timeindex, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,205] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 01:13:30,206] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-02-19 01:13:30,209] WARN [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-20\00000000000000000000.index, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,210] WARN [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-20\00000000000000000000.timeindex, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,212] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 01:13:30,216] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2019-02-19 01:13:30,219] WARN [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-21\00000000000000000000.index, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,220] WARN [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-21\00000000000000000000.timeindex, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,222] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 01:13:30,224] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-02-19 01:13:30,228] WARN [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-22\00000000000000000000.index, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,228] WARN [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-22\00000000000000000000.timeindex, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,229] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 01:13:30,232] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-02-19 01:13:30,236] WARN [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-23\00000000000000000000.index, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,237] WARN [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-23\00000000000000000000.timeindex, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,238] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 01:13:30,239] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-02-19 01:13:30,244] WARN [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-24\00000000000000000000.index, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,244] WARN [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-24\00000000000000000000.timeindex, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,245] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 01:13:30,246] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-02-19 01:13:30,249] WARN [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-25\00000000000000000000.index, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,250] WARN [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-25\00000000000000000000.timeindex, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,253] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 01:13:30,254] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-02-19 01:13:30,256] WARN [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-26\00000000000000000000.index, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,257] WARN [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-26\00000000000000000000.timeindex, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,258] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 01:13:30,259] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-02-19 01:13:30,263] WARN [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-27\00000000000000000000.index, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,264] WARN [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-27\00000000000000000000.timeindex, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,265] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 01:13:30,266] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-02-19 01:13:30,269] WARN [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-28\00000000000000000000.index, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,269] WARN [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-28\00000000000000000000.timeindex, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,271] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 01:13:30,274] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-02-19 01:13:30,278] WARN [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-29\00000000000000000000.index, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,278] WARN [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-29\00000000000000000000.timeindex, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,280] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 01:13:30,282] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-02-19 01:13:30,286] WARN [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-3\00000000000000000000.index, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,286] WARN [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-3\00000000000000000000.timeindex, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,288] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 01:13:30,289] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-02-19 01:13:30,293] WARN [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-30\00000000000000000000.index, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,294] WARN [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-30\00000000000000000000.timeindex, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,296] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 01:13:30,297] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-02-19 01:13:30,302] WARN [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-31\00000000000000000000.index, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,303] WARN [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-31\00000000000000000000.timeindex, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,305] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 01:13:30,306] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-02-19 01:13:30,308] WARN [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000000.index, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,309] WARN [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000000.timeindex, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,312] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 01:13:30,313] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-02-19 01:13:30,316] WARN [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-33\00000000000000000000.index, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,316] WARN [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-33\00000000000000000000.timeindex, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,317] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 01:13:30,318] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-02-19 01:13:30,321] WARN [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-34\00000000000000000000.index, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,321] WARN [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-34\00000000000000000000.timeindex, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,323] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 01:13:30,324] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-02-19 01:13:30,327] WARN [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-35\00000000000000000000.index, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,327] WARN [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-35\00000000000000000000.timeindex, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,329] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 01:13:30,331] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-02-19 01:13:30,335] WARN [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-36\00000000000000000000.index, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,335] WARN [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-36\00000000000000000000.timeindex, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,336] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 01:13:30,337] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-02-19 01:13:30,344] WARN [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-37\00000000000000000000.index, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,345] WARN [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-37\00000000000000000000.timeindex, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,346] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 01:13:30,348] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-02-19 01:13:30,352] WARN [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-38\00000000000000000000.index, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,353] WARN [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-38\00000000000000000000.timeindex, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,355] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 01:13:30,356] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-02-19 01:13:30,360] WARN [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-39\00000000000000000000.index, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,361] WARN [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-39\00000000000000000000.timeindex, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,363] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 01:13:30,364] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-02-19 01:13:30,367] WARN [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-4\00000000000000000000.index, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,367] WARN [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-4\00000000000000000000.timeindex, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,369] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 01:13:30,371] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-02-19 01:13:30,376] WARN [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-40\00000000000000000000.index, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,376] WARN [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-40\00000000000000000000.timeindex, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,378] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 01:13:30,379] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-02-19 01:13:30,383] WARN [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-41\00000000000000000000.index, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,384] WARN [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-41\00000000000000000000.timeindex, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,385] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 01:13:30,386] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-02-19 01:13:30,388] WARN [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-42\00000000000000000000.index, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,389] WARN [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-42\00000000000000000000.timeindex, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,392] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 01:13:30,394] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-02-19 01:13:30,397] WARN [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-43\00000000000000000000.index, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,397] WARN [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-43\00000000000000000000.timeindex, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,399] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 01:13:30,401] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-02-19 01:13:30,404] WARN [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-44\00000000000000000000.index, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,405] WARN [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-44\00000000000000000000.timeindex, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,406] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 01:13:30,407] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-02-19 01:13:30,410] WARN [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-45\00000000000000000000.index, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,411] WARN [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-45\00000000000000000000.timeindex, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,414] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 01:13:30,414] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-02-19 01:13:30,416] WARN [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-46\00000000000000000000.index, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,417] WARN [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-46\00000000000000000000.timeindex, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,418] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 01:13:30,419] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-02-19 01:13:30,423] WARN [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-47\00000000000000000000.index, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,424] WARN [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-47\00000000000000000000.timeindex, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,425] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 01:13:30,426] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-02-19 01:13:30,429] WARN [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-48\00000000000000000000.index, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,431] WARN [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-48\00000000000000000000.timeindex, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,433] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 01:13:30,434] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-02-19 01:13:30,436] WARN [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-49\00000000000000000000.index, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,437] WARN [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-49\00000000000000000000.timeindex, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,438] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 01:13:30,439] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-02-19 01:13:30,443] WARN [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-5\00000000000000000000.index, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,444] WARN [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-5\00000000000000000000.timeindex, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,445] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 01:13:30,446] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-02-19 01:13:30,448] WARN [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-6\00000000000000000000.index, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,448] WARN [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-6\00000000000000000000.timeindex, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,450] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 01:13:30,451] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-02-19 01:13:30,454] WARN [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-7\00000000000000000000.index, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,455] WARN [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-7\00000000000000000000.timeindex, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,473] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 01:13:30,474] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-02-19 01:13:30,477] WARN [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-8\00000000000000000000.index, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,478] WARN [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-8\00000000000000000000.timeindex, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,480] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 01:13:30,481] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-02-19 01:13:30,483] WARN [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-9\00000000000000000000.index, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,484] WARN [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\__consumer_offsets-9\00000000000000000000.timeindex, with no corresponding log file. (kafka.log.Log)
[2019-02-19 01:13:30,487] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 01:13:30,488] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-02-19 01:13:30,491] INFO Logs loading complete in 726 ms. (kafka.log.LogManager)
[2019-02-19 01:13:30,503] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-02-19 01:13:30,504] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-02-19 01:13:30,707] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-02-19 01:13:30,734] INFO [SocketServer brokerId=0] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-02-19 01:13:30,768] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-02-19 01:13:30,769] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-02-19 01:13:30,770] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-02-19 01:13:30,784] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-02-19 01:13:35,367] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-02-19 01:13:35,385] INFO Result of znode creation at /brokers/ids/0 is: OK (kafka.zk.KafkaZkClient)
[2019-02-19 01:13:35,387] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(DESKTOP-6IV0LP1,9092,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-02-19 01:13:35,389] WARN No meta.properties file under dir D:\tmp\kafka-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-02-19 01:13:35,506] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-02-19 01:13:35,506] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-02-19 01:13:35,506] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-02-19 01:13:35,546] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-02-19 01:13:35,550] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-02-19 01:13:35,564] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 10 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:35,583] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:3000,blockEndProducerId:3999) by writing to Zk with path version 4 (kafka.coordinator.transaction.ProducerIdManager)
[2019-02-19 01:13:35,610] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-02-19 01:13:35,612] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-02-19 01:13:35,613] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-02-19 01:13:35,656] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-02-19 01:13:35,696] INFO [SocketServer brokerId=0] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-02-19 01:13:35,708] INFO Kafka version : 2.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-02-19 01:13:35,713] INFO Kafka commitId : 809be928f1ae004e (org.apache.kafka.common.utils.AppInfoParser)
[2019-02-19 01:13:35,722] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2019-02-19 01:13:35,770] INFO Got user-level KeeperException when processing sessionid:0x1000573f3780002 type:multi cxid:0x7c zxid:0xee txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/reassign_partitions Error:KeeperErrorCode = NoNode for /admin/reassign_partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-19 01:13:35,813] INFO Got user-level KeeperException when processing sessionid:0x1000573f3780002 type:multi cxid:0x82 zxid:0xef txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-19 01:13:35,820] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, msg-topic-2, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, emp-topic-0, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, empjson-topic-0, emp-topic-1, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, first-topic-1, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, first-topic-0, test-topic-0, msg-topic-0, msg-topic-1, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-02-19 01:13:35,850] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 01:13:35,899] INFO [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 01:13:35,956] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 01:13:35,957] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 01:13:35,985] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 01:13:35,986] INFO [Partition __consumer_offsets-48 broker=0] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 01:13:36,018] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 01:13:36,021] INFO [Partition __consumer_offsets-10 broker=0] __consumer_offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 01:13:36,051] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 01:13:36,051] INFO [Partition __consumer_offsets-45 broker=0] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 01:13:36,076] INFO Replica loaded for partition first-topic-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 01:13:36,077] INFO [Partition first-topic-1 broker=0] first-topic-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 01:13:36,114] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 01:13:36,116] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 01:13:36,143] INFO Replica loaded for partition msg-topic-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 01:13:36,143] INFO [Partition msg-topic-2 broker=0] msg-topic-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 01:13:36,168] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 01:13:36,168] INFO [Partition __consumer_offsets-7 broker=0] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 01:13:36,192] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 01:13:36,193] INFO [Partition __consumer_offsets-42 broker=0] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 01:13:36,219] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 01:13:36,219] INFO [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 01:13:36,261] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 01:13:36,261] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 01:13:36,291] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 01:13:36,292] INFO [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 01:13:36,317] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 01:13:36,317] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 01:13:36,361] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 01:13:36,366] INFO [Partition __consumer_offsets-39 broker=0] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 01:13:36,393] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 01:13:36,393] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 01:13:36,426] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 01:13:36,427] INFO [Partition __consumer_offsets-36 broker=0] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 01:13:36,468] INFO Replica loaded for partition test-topic-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 01:13:36,472] INFO [Partition test-topic-0 broker=0] test-topic-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 01:13:36,501] INFO Replica loaded for partition emp-topic-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 01:13:36,501] INFO [Partition emp-topic-1 broker=0] emp-topic-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 01:13:36,534] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 01:13:36,534] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 01:13:36,560] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 01:13:36,560] INFO [Partition __consumer_offsets-33 broker=0] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 01:13:36,639] INFO Replica loaded for partition msg-topic-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 01:13:36,661] INFO [Partition msg-topic-0 broker=0] msg-topic-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 01:13:36,697] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 01:13:36,702] INFO [Partition __consumer_offsets-49 broker=0] __consumer_offsets-49 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 01:13:36,779] INFO Replica loaded for partition empjson-topic-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 01:13:36,780] INFO [Partition empjson-topic-0 broker=0] empjson-topic-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 01:13:36,828] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 01:13:36,841] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 01:13:36,916] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 01:13:36,922] INFO [Partition __consumer_offsets-30 broker=0] __consumer_offsets-30 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 01:13:36,994] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 01:13:37,028] INFO [Partition __consumer_offsets-46 broker=0] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 01:13:37,122] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 01:13:37,124] INFO [Partition __consumer_offsets-27 broker=0] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 01:13:37,152] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 01:13:37,153] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 01:13:37,186] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 01:13:37,186] INFO [Partition __consumer_offsets-24 broker=0] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 01:13:37,227] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 01:13:37,230] INFO [Partition __consumer_offsets-43 broker=0] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 01:13:37,259] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 01:13:37,259] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 01:13:37,311] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 01:13:37,311] INFO [Partition __consumer_offsets-21 broker=0] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 01:13:37,391] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 01:13:37,394] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 01:13:37,426] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 01:13:37,464] INFO [Partition __consumer_offsets-40 broker=0] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 01:13:37,535] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 01:13:37,537] INFO [Partition __consumer_offsets-37 broker=0] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 01:13:37,569] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 01:13:37,570] INFO [Partition __consumer_offsets-18 broker=0] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 01:13:37,619] INFO Replica loaded for partition msg-topic-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 01:13:37,627] INFO [Partition msg-topic-1 broker=0] msg-topic-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 01:13:37,685] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 01:13:37,804] INFO [Partition __consumer_offsets-34 broker=0] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 01:13:38,637] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 01:13:38,810] INFO [Partition __consumer_offsets-15 broker=0] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 01:13:39,045] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 01:13:39,054] INFO [Partition __consumer_offsets-12 broker=0] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 01:13:39,134] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 01:13:39,135] INFO [Partition __consumer_offsets-31 broker=0] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 01:13:39,203] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 01:13:39,208] INFO [Partition __consumer_offsets-9 broker=0] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 01:13:39,245] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 01:13:39,247] INFO [Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 01:13:39,304] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 01:13:39,305] INFO [Partition __consumer_offsets-19 broker=0] __consumer_offsets-19 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 01:13:39,340] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 01:13:39,345] INFO [Partition __consumer_offsets-28 broker=0] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 01:13:39,378] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 01:13:39,390] INFO [Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 01:13:39,422] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 01:13:39,451] INFO [Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 01:13:39,595] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 01:13:39,613] INFO [Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 01:13:39,665] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 01:13:39,666] INFO [Partition __consumer_offsets-6 broker=0] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 01:13:39,706] INFO Replica loaded for partition emp-topic-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 01:13:39,708] INFO [Partition emp-topic-0 broker=0] emp-topic-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 01:13:39,745] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 01:13:39,745] INFO [Partition __consumer_offsets-25 broker=0] __consumer_offsets-25 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 01:13:39,777] INFO Replica loaded for partition first-topic-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 01:13:39,777] INFO [Partition first-topic-0 broker=0] first-topic-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 01:13:39,801] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 01:13:39,801] INFO [Partition __consumer_offsets-16 broker=0] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 01:13:39,826] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 01:13:39,827] INFO [Partition __consumer_offsets-22 broker=0] __consumer_offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 01:13:39,852] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 01:13:39,852] INFO [Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 01:13:39,893] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 01:13:39,894] INFO [Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 01:13:39,927] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 01:13:39,927] INFO [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 01:13:39,968] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 01:13:39,969] INFO [Partition __consumer_offsets-13 broker=0] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 01:13:40,027] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,033] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,034] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,035] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,035] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,035] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,036] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,036] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,036] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,037] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,037] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,037] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,038] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,038] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,038] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,039] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,039] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,039] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,039] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,040] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,040] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 7 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,044] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,045] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,045] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,046] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,046] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,046] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,046] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,047] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,047] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,047] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,048] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,048] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,048] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,048] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,048] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,049] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,049] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,049] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,049] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,049] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,050] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,050] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,050] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,050] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,051] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,051] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,051] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,051] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,052] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,055] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,056] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,057] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,058] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,058] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,058] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,058] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,058] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,059] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,059] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,059] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,060] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,060] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,060] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,060] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,061] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,061] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,061] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,061] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,062] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,062] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,063] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,063] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,063] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,063] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,064] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,072] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,073] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,074] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,075] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,075] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,076] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,076] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,077] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,078] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,078] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,079] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,082] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,082] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,083] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,083] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,083] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,084] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,084] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,084] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,085] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,085] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,085] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,085] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,086] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:13:40,114] INFO [GroupCoordinator 0]: Preparing to rebalance group test-group in state PreparingRebalance with old generation 0 (__consumer_offsets-12) (reason: Adding new member consumer-1-36019671-abfe-479f-8d74-3fcfe898aac5) (kafka.coordinator.group.GroupCoordinator)
[2019-02-19 01:13:40,121] INFO [GroupCoordinator 0]: Stabilized group test-group generation 1 (__consumer_offsets-12) (kafka.coordinator.group.GroupCoordinator)
[2019-02-19 01:13:40,131] INFO [GroupCoordinator 0]: Assignment received from leader for group test-group for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-02-19 01:23:35,553] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:33:35,549] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:43:35,549] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 01:53:35,549] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 02:03:35,548] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 02:13:35,550] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 02:23:35,549] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 02:28:05,779] INFO [GroupCoordinator 0]: Member consumer-1-36019671-abfe-479f-8d74-3fcfe898aac5 in group test-group has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-02-19 02:28:05,781] INFO [GroupCoordinator 0]: Preparing to rebalance group test-group in state PreparingRebalance with old generation 1 (__consumer_offsets-12) (reason: removing member consumer-1-36019671-abfe-479f-8d74-3fcfe898aac5 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-02-19 02:28:05,784] INFO [GroupCoordinator 0]: Group test-group with generation 2 is now empty (__consumer_offsets-12) (kafka.coordinator.group.GroupCoordinator)
[2019-02-19 02:33:35,554] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 02:38:53,321] WARN Session 0x1000573f3780002 for server localhost/127.0.0.1:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.io.IOException: An existing connection was forcibly closed by the remote host
	at sun.nio.ch.SocketDispatcher.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:68)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:366)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1145)
[2019-02-19 02:38:54,935] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-02-19 02:38:55,938] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2019-02-19 02:38:57,239] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-02-19 02:38:58,241] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2019-02-19 02:39:00,228] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-02-19 02:42:53,616] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-02-19 02:42:53,618] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-02-19 02:42:53,618] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-02-19 02:42:53,618] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-02-19 02:42:53,619] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-02-19 02:42:53,631] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-02-19 02:42:53,632] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-02-19 02:42:58,166] INFO Server environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-02-19 02:42:58,167] INFO Server environment:host.name=DESKTOP-6IV0LP1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-02-19 02:42:58,167] INFO Server environment:java.version=1.8.0_201 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-02-19 02:42:58,167] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-02-19 02:42:58,168] INFO Server environment:java.home=C:\Program Files\Java\jdk1.8.0_201\jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-02-19 02:42:58,168] INFO Server environment:java.class.path=D:\Software\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;D:\Software\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;D:\Software\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;D:\Software\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;D:\Software\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;D:\Software\kafka_2.12-2.1.0\libs\compileScala.mapping;D:\Software\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;D:\Software\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\guava-20.0.jar;D:\Software\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;D:\Software\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;D:\Software\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;D:\Software\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;D:\Software\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;D:\Software\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;D:\Software\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;D:\Software\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;D:\Software\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;D:\Software\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;D:\Software\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;D:\Software\kafka_2.12-2.1.0\libs\javax.inject-1.jar;D:\Software\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;D:\Software\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;D:\Software\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;D:\Software\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;D:\Software\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;D:\Software\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;D:\Software\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;D:\Software\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;D:\Software\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;D:\Software\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;D:\Software\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;D:\Software\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;D:\Software\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;D:\Software\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;D:\Software\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;D:\Software\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;D:\Software\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;D:\Software\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;D:\Software\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;D:\Software\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;D:\Software\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;D:\Software\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;D:\Software\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;D:\Software\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;D:\Software\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;D:\Software\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;D:\Software\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;D:\Software\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-02-19 02:42:58,170] INFO Server environment:java.library.path=C:\Program Files\Java\jdk1.8.0_201\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;%JAVA_HOME%\bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Users\Administrator\AppData\Local\Microsoft\WindowsApps;;. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-02-19 02:42:58,170] INFO Server environment:java.io.tmpdir=C:\Users\ADMINI~1\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-02-19 02:42:58,171] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-02-19 02:42:58,171] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-02-19 02:42:58,172] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-02-19 02:42:58,172] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-02-19 02:42:58,173] INFO Server environment:user.name=Administrator (org.apache.zookeeper.server.ZooKeeperServer)
[2019-02-19 02:42:58,173] INFO Server environment:user.home=C:\Users\Administrator (org.apache.zookeeper.server.ZooKeeperServer)
[2019-02-19 02:42:58,174] INFO Server environment:user.dir=D:\Software\kafka_2.12-2.1.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-02-19 02:42:58,188] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-02-19 02:42:58,188] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-02-19 02:42:58,190] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-02-19 02:42:58,219] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-02-19 02:42:58,221] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-02-19 02:44:13,827] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-02-19 02:44:14,315] INFO starting (kafka.server.KafkaServer)
[2019-02-19 02:44:14,317] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-02-19 02:44:14,335] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-02-19 02:44:18,883] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-02-19 02:44:18,884] INFO Client environment:host.name=DESKTOP-6IV0LP1 (org.apache.zookeeper.ZooKeeper)
[2019-02-19 02:44:18,885] INFO Client environment:java.version=1.8.0_201 (org.apache.zookeeper.ZooKeeper)
[2019-02-19 02:44:18,885] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-02-19 02:44:18,885] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_201\jre (org.apache.zookeeper.ZooKeeper)
[2019-02-19 02:44:18,885] INFO Client environment:java.class.path=D:\Software\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;D:\Software\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;D:\Software\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;D:\Software\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;D:\Software\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;D:\Software\kafka_2.12-2.1.0\libs\compileScala.mapping;D:\Software\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;D:\Software\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\guava-20.0.jar;D:\Software\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;D:\Software\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;D:\Software\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;D:\Software\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;D:\Software\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;D:\Software\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;D:\Software\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;D:\Software\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;D:\Software\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;D:\Software\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;D:\Software\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;D:\Software\kafka_2.12-2.1.0\libs\javax.inject-1.jar;D:\Software\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;D:\Software\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;D:\Software\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;D:\Software\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;D:\Software\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;D:\Software\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;D:\Software\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;D:\Software\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;D:\Software\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;D:\Software\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;D:\Software\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;D:\Software\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;D:\Software\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;D:\Software\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;D:\Software\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;D:\Software\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;D:\Software\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;D:\Software\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;D:\Software\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;D:\Software\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;D:\Software\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;D:\Software\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;D:\Software\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;D:\Software\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;D:\Software\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;D:\Software\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;D:\Software\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;D:\Software\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.ZooKeeper)
[2019-02-19 02:44:18,887] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_201\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;%JAVA_HOME%\bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Users\Administrator\AppData\Local\Microsoft\WindowsApps;;. (org.apache.zookeeper.ZooKeeper)
[2019-02-19 02:44:18,887] INFO Client environment:java.io.tmpdir=C:\Users\ADMINI~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-02-19 02:44:18,887] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-02-19 02:44:18,888] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-02-19 02:44:18,888] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-02-19 02:44:18,889] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-02-19 02:44:18,889] INFO Client environment:user.name=Administrator (org.apache.zookeeper.ZooKeeper)
[2019-02-19 02:44:18,890] INFO Client environment:user.home=C:\Users\Administrator (org.apache.zookeeper.ZooKeeper)
[2019-02-19 02:44:18,890] INFO Client environment:user.dir=D:\Software\kafka_2.12-2.1.0 (org.apache.zookeeper.ZooKeeper)
[2019-02-19 02:44:18,893] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@78b66d36 (org.apache.zookeeper.ZooKeeper)
[2019-02-19 02:44:18,931] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-02-19 02:44:18,932] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-02-19 02:44:18,935] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-02-19 02:44:18,935] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:57193 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-02-19 02:44:18,940] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:57193 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-02-19 02:44:18,942] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-02-19 02:44:18,972] INFO Established session 0x10006c52e520000 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:57193 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-02-19 02:44:18,974] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x10006c52e520000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-02-19 02:44:18,978] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-02-19 02:44:19,053] INFO Got user-level KeeperException when processing sessionid:0x10006c52e520000 type:create cxid:0x2 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-19 02:44:19,125] INFO Got user-level KeeperException when processing sessionid:0x10006c52e520000 type:create cxid:0x6 zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-19 02:44:19,176] INFO Got user-level KeeperException when processing sessionid:0x10006c52e520000 type:create cxid:0x9 zxid:0xa txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-19 02:44:19,538] INFO Got user-level KeeperException when processing sessionid:0x10006c52e520000 type:create cxid:0x15 zxid:0x15 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-19 02:44:19,610] INFO Cluster ID = GgNQQO0OSsCxcUz7n4EETw (kafka.server.KafkaServer)
[2019-02-19 02:44:19,633] WARN No meta.properties file under dir D:\tmp\kafka1-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-02-19 02:44:19,705] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka1-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9091
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-02-19 02:44:19,716] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka1-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9091
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-02-19 02:44:19,741] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-02-19 02:44:19,741] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-02-19 02:44:19,745] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-02-19 02:44:19,770] INFO Log directory D:\tmp\kafka1-logs not found, creating it. (kafka.log.LogManager)
[2019-02-19 02:44:19,779] INFO Loading logs. (kafka.log.LogManager)
[2019-02-19 02:44:19,787] INFO Logs loading complete in 8 ms. (kafka.log.LogManager)
[2019-02-19 02:44:19,801] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-02-19 02:44:19,805] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-02-19 02:44:20,061] INFO Awaiting socket connections on 0.0.0.0:9091. (kafka.network.Acceptor)
[2019-02-19 02:44:20,092] INFO [SocketServer brokerId=1] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-02-19 02:44:20,115] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-02-19 02:44:20,116] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-02-19 02:44:20,116] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-02-19 02:44:20,131] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-02-19 02:44:24,702] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-02-19 02:44:24,728] INFO Result of znode creation at /brokers/ids/1 is: OK (kafka.zk.KafkaZkClient)
[2019-02-19 02:44:24,731] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(DESKTOP-6IV0LP1,9091,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-02-19 02:44:24,734] WARN No meta.properties file under dir D:\tmp\kafka1-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-02-19 02:44:24,833] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-02-19 02:44:24,836] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-02-19 02:44:24,837] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-02-19 02:44:24,860] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2019-02-19 02:44:24,867] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-02-19 02:44:24,868] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-02-19 02:44:24,874] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 02:44:24,937] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
[2019-02-19 02:44:24,960] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-02-19 02:44:24,967] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-02-19 02:44:24,967] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-02-19 02:44:25,039] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-02-19 02:44:25,052] INFO Got user-level KeeperException when processing sessionid:0x10006c52e520000 type:multi cxid:0x33 zxid:0x1c txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/reassign_partitions Error:KeeperErrorCode = NoNode for /admin/reassign_partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-19 02:44:25,081] INFO [SocketServer brokerId=1] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-02-19 02:44:25,085] INFO Kafka version : 2.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-02-19 02:44:25,089] INFO Kafka commitId : 809be928f1ae004e (org.apache.kafka.common.utils.AppInfoParser)
[2019-02-19 02:44:25,088] INFO Got user-level KeeperException when processing sessionid:0x10006c52e520000 type:multi cxid:0x38 zxid:0x1d txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-19 02:44:25,091] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2019-02-19 02:44:32,565] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-02-19 02:44:33,071] INFO starting (kafka.server.KafkaServer)
[2019-02-19 02:44:33,072] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-02-19 02:44:33,090] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-02-19 02:44:36,689] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-02-19 02:44:37,177] INFO starting (kafka.server.KafkaServer)
[2019-02-19 02:44:37,179] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-02-19 02:44:37,196] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-02-19 02:44:37,630] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-02-19 02:44:37,631] INFO Client environment:host.name=DESKTOP-6IV0LP1 (org.apache.zookeeper.ZooKeeper)
[2019-02-19 02:44:37,631] INFO Client environment:java.version=1.8.0_201 (org.apache.zookeeper.ZooKeeper)
[2019-02-19 02:44:37,631] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-02-19 02:44:37,632] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_201\jre (org.apache.zookeeper.ZooKeeper)
[2019-02-19 02:44:37,632] INFO Client environment:java.class.path=D:\Software\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;D:\Software\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;D:\Software\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;D:\Software\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;D:\Software\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;D:\Software\kafka_2.12-2.1.0\libs\compileScala.mapping;D:\Software\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;D:\Software\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\guava-20.0.jar;D:\Software\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;D:\Software\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;D:\Software\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;D:\Software\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;D:\Software\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;D:\Software\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;D:\Software\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;D:\Software\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;D:\Software\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;D:\Software\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;D:\Software\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;D:\Software\kafka_2.12-2.1.0\libs\javax.inject-1.jar;D:\Software\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;D:\Software\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;D:\Software\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;D:\Software\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;D:\Software\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;D:\Software\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;D:\Software\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;D:\Software\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;D:\Software\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;D:\Software\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;D:\Software\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;D:\Software\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;D:\Software\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;D:\Software\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;D:\Software\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;D:\Software\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;D:\Software\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;D:\Software\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;D:\Software\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;D:\Software\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;D:\Software\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;D:\Software\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;D:\Software\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;D:\Software\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;D:\Software\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;D:\Software\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;D:\Software\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;D:\Software\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.ZooKeeper)
[2019-02-19 02:44:37,634] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_201\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;%JAVA_HOME%\bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Users\Administrator\AppData\Local\Microsoft\WindowsApps;;. (org.apache.zookeeper.ZooKeeper)
[2019-02-19 02:44:37,635] INFO Client environment:java.io.tmpdir=C:\Users\ADMINI~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-02-19 02:44:37,635] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-02-19 02:44:37,636] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-02-19 02:44:37,636] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-02-19 02:44:37,637] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-02-19 02:44:37,637] INFO Client environment:user.name=Administrator (org.apache.zookeeper.ZooKeeper)
[2019-02-19 02:44:37,638] INFO Client environment:user.home=C:\Users\Administrator (org.apache.zookeeper.ZooKeeper)
[2019-02-19 02:44:37,638] INFO Client environment:user.dir=D:\Software\kafka_2.12-2.1.0 (org.apache.zookeeper.ZooKeeper)
[2019-02-19 02:44:37,642] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@78b66d36 (org.apache.zookeeper.ZooKeeper)
[2019-02-19 02:44:37,677] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-02-19 02:44:37,679] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-02-19 02:44:37,682] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:57211 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-02-19 02:44:37,682] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-02-19 02:44:37,687] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:57211 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-02-19 02:44:37,715] INFO Established session 0x10006c52e520001 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:57211 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-02-19 02:44:37,718] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x10006c52e520001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-02-19 02:44:37,726] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-02-19 02:44:37,807] INFO Got user-level KeeperException when processing sessionid:0x10006c52e520001 type:create cxid:0x1 zxid:0x1f txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-19 02:44:37,834] INFO Got user-level KeeperException when processing sessionid:0x10006c52e520001 type:create cxid:0x2 zxid:0x20 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-19 02:44:37,858] INFO Got user-level KeeperException when processing sessionid:0x10006c52e520001 type:create cxid:0x3 zxid:0x21 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-19 02:44:37,874] INFO Got user-level KeeperException when processing sessionid:0x10006c52e520001 type:create cxid:0x4 zxid:0x22 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-19 02:44:37,892] INFO Got user-level KeeperException when processing sessionid:0x10006c52e520001 type:create cxid:0x5 zxid:0x23 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-19 02:44:37,908] INFO Got user-level KeeperException when processing sessionid:0x10006c52e520001 type:create cxid:0x6 zxid:0x24 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-19 02:44:37,925] INFO Got user-level KeeperException when processing sessionid:0x10006c52e520001 type:create cxid:0x7 zxid:0x25 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-19 02:44:37,940] INFO Got user-level KeeperException when processing sessionid:0x10006c52e520001 type:create cxid:0x8 zxid:0x26 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-19 02:44:37,958] INFO Got user-level KeeperException when processing sessionid:0x10006c52e520001 type:create cxid:0x9 zxid:0x27 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-19 02:44:37,974] INFO Got user-level KeeperException when processing sessionid:0x10006c52e520001 type:create cxid:0xa zxid:0x28 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-19 02:44:37,991] INFO Got user-level KeeperException when processing sessionid:0x10006c52e520001 type:create cxid:0xb zxid:0x29 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-19 02:44:38,008] INFO Got user-level KeeperException when processing sessionid:0x10006c52e520001 type:create cxid:0xc zxid:0x2a txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-19 02:44:38,025] INFO Got user-level KeeperException when processing sessionid:0x10006c52e520001 type:create cxid:0xd zxid:0x2b txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-19 02:44:38,203] INFO Cluster ID = GgNQQO0OSsCxcUz7n4EETw (kafka.server.KafkaServer)
[2019-02-19 02:44:38,207] WARN No meta.properties file under dir D:\tmp\kafka2-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-02-19 02:44:38,278] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka2-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-02-19 02:44:38,288] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka2-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-02-19 02:44:38,315] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-02-19 02:44:38,317] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-02-19 02:44:38,315] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-02-19 02:44:38,338] INFO Log directory D:\tmp\kafka2-logs not found, creating it. (kafka.log.LogManager)
[2019-02-19 02:44:38,346] INFO Loading logs. (kafka.log.LogManager)
[2019-02-19 02:44:38,354] INFO Logs loading complete in 8 ms. (kafka.log.LogManager)
[2019-02-19 02:44:38,367] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-02-19 02:44:38,372] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-02-19 02:44:38,632] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-02-19 02:44:38,664] INFO [SocketServer brokerId=2] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-02-19 02:44:38,684] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-02-19 02:44:38,685] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-02-19 02:44:38,685] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-02-19 02:44:38,698] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-02-19 02:44:41,739] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-02-19 02:44:41,740] INFO Client environment:host.name=DESKTOP-6IV0LP1 (org.apache.zookeeper.ZooKeeper)
[2019-02-19 02:44:41,740] INFO Client environment:java.version=1.8.0_201 (org.apache.zookeeper.ZooKeeper)
[2019-02-19 02:44:41,740] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-02-19 02:44:41,741] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_201\jre (org.apache.zookeeper.ZooKeeper)
[2019-02-19 02:44:41,741] INFO Client environment:java.class.path=D:\Software\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;D:\Software\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;D:\Software\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;D:\Software\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;D:\Software\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;D:\Software\kafka_2.12-2.1.0\libs\compileScala.mapping;D:\Software\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;D:\Software\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\guava-20.0.jar;D:\Software\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;D:\Software\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;D:\Software\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;D:\Software\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;D:\Software\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;D:\Software\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;D:\Software\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;D:\Software\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;D:\Software\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;D:\Software\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;D:\Software\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;D:\Software\kafka_2.12-2.1.0\libs\javax.inject-1.jar;D:\Software\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;D:\Software\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;D:\Software\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;D:\Software\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;D:\Software\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;D:\Software\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;D:\Software\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;D:\Software\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;D:\Software\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;D:\Software\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;D:\Software\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;D:\Software\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;D:\Software\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;D:\Software\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;D:\Software\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;D:\Software\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;D:\Software\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;D:\Software\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;D:\Software\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;D:\Software\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;D:\Software\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;D:\Software\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;D:\Software\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;D:\Software\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;D:\Software\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;D:\Software\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;D:\Software\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;D:\Software\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;D:\Software\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;D:\Software\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.ZooKeeper)
[2019-02-19 02:44:41,742] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_201\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;%JAVA_HOME%\bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Users\Administrator\AppData\Local\Microsoft\WindowsApps;;. (org.apache.zookeeper.ZooKeeper)
[2019-02-19 02:44:41,742] INFO Client environment:java.io.tmpdir=C:\Users\ADMINI~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-02-19 02:44:41,744] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-02-19 02:44:41,744] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-02-19 02:44:41,745] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-02-19 02:44:41,746] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-02-19 02:44:41,746] INFO Client environment:user.name=Administrator (org.apache.zookeeper.ZooKeeper)
[2019-02-19 02:44:41,746] INFO Client environment:user.home=C:\Users\Administrator (org.apache.zookeeper.ZooKeeper)
[2019-02-19 02:44:41,747] INFO Client environment:user.dir=D:\Software\kafka_2.12-2.1.0 (org.apache.zookeeper.ZooKeeper)
[2019-02-19 02:44:41,749] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@78b66d36 (org.apache.zookeeper.ZooKeeper)
[2019-02-19 02:44:41,778] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-02-19 02:44:41,779] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-02-19 02:44:41,781] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:57222 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-02-19 02:44:41,781] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-02-19 02:44:41,784] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:57222 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-02-19 02:44:41,800] INFO Established session 0x10006c52e520002 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:57222 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-02-19 02:44:41,802] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x10006c52e520002, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-02-19 02:44:41,806] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-02-19 02:44:41,849] INFO Got user-level KeeperException when processing sessionid:0x10006c52e520002 type:create cxid:0x1 zxid:0x2d txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-19 02:44:41,883] INFO Got user-level KeeperException when processing sessionid:0x10006c52e520002 type:create cxid:0x2 zxid:0x2e txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-19 02:44:41,900] INFO Got user-level KeeperException when processing sessionid:0x10006c52e520002 type:create cxid:0x3 zxid:0x2f txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-19 02:44:41,917] INFO Got user-level KeeperException when processing sessionid:0x10006c52e520002 type:create cxid:0x4 zxid:0x30 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-19 02:44:41,934] INFO Got user-level KeeperException when processing sessionid:0x10006c52e520002 type:create cxid:0x5 zxid:0x31 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-19 02:44:41,951] INFO Got user-level KeeperException when processing sessionid:0x10006c52e520002 type:create cxid:0x6 zxid:0x32 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-19 02:44:41,967] INFO Got user-level KeeperException when processing sessionid:0x10006c52e520002 type:create cxid:0x7 zxid:0x33 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-19 02:44:41,985] INFO Got user-level KeeperException when processing sessionid:0x10006c52e520002 type:create cxid:0x8 zxid:0x34 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-19 02:44:42,004] INFO Got user-level KeeperException when processing sessionid:0x10006c52e520002 type:create cxid:0x9 zxid:0x35 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-19 02:44:42,017] INFO Got user-level KeeperException when processing sessionid:0x10006c52e520002 type:create cxid:0xa zxid:0x36 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-19 02:44:42,037] INFO Got user-level KeeperException when processing sessionid:0x10006c52e520002 type:create cxid:0xb zxid:0x37 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-19 02:44:42,051] INFO Got user-level KeeperException when processing sessionid:0x10006c52e520002 type:create cxid:0xc zxid:0x38 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-19 02:44:42,070] INFO Got user-level KeeperException when processing sessionid:0x10006c52e520002 type:create cxid:0xd zxid:0x39 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-19 02:44:42,242] INFO Cluster ID = GgNQQO0OSsCxcUz7n4EETw (kafka.server.KafkaServer)
[2019-02-19 02:44:42,246] WARN No meta.properties file under dir D:\tmp\kafka3-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-02-19 02:44:42,316] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka3-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9093
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-02-19 02:44:42,327] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka3-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9093
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-02-19 02:44:42,354] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-02-19 02:44:42,354] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-02-19 02:44:42,357] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-02-19 02:44:42,378] INFO Log directory D:\tmp\kafka3-logs not found, creating it. (kafka.log.LogManager)
[2019-02-19 02:44:42,386] INFO Loading logs. (kafka.log.LogManager)
[2019-02-19 02:44:42,394] INFO Logs loading complete in 8 ms. (kafka.log.LogManager)
[2019-02-19 02:44:42,409] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-02-19 02:44:42,415] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-02-19 02:44:42,678] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2019-02-19 02:44:42,712] INFO [SocketServer brokerId=3] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-02-19 02:44:42,734] INFO [ExpirationReaper-3-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-02-19 02:44:42,735] INFO [ExpirationReaper-3-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-02-19 02:44:42,735] INFO [ExpirationReaper-3-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-02-19 02:44:42,749] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-02-19 02:44:43,317] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-02-19 02:44:43,337] INFO Result of znode creation at /brokers/ids/2 is: OK (kafka.zk.KafkaZkClient)
[2019-02-19 02:44:43,338] INFO Registered broker 2 at path /brokers/ids/2 with addresses: ArrayBuffer(EndPoint(DESKTOP-6IV0LP1,9092,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-02-19 02:44:43,341] WARN No meta.properties file under dir D:\tmp\kafka2-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-02-19 02:44:43,441] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-02-19 02:44:43,442] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-02-19 02:44:43,442] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-02-19 02:44:43,459] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-02-19 02:44:43,460] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-02-19 02:44:43,467] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 02:44:43,496] INFO [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:1000,blockEndProducerId:1999) by writing to Zk with path version 2 (kafka.coordinator.transaction.ProducerIdManager)
[2019-02-19 02:44:43,517] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-02-19 02:44:43,520] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-02-19 02:44:43,520] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-02-19 02:44:43,558] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-02-19 02:44:43,571] INFO [SocketServer brokerId=2] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-02-19 02:44:43,576] INFO Kafka version : 2.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-02-19 02:44:43,579] INFO Kafka commitId : 809be928f1ae004e (org.apache.kafka.common.utils.AppInfoParser)
[2019-02-19 02:44:43,582] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2019-02-19 02:44:47,367] INFO Creating /brokers/ids/3 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-02-19 02:44:52,413] INFO Result of znode creation at /brokers/ids/3 is: OK (kafka.zk.KafkaZkClient)
[2019-02-19 02:44:52,415] INFO Registered broker 3 at path /brokers/ids/3 with addresses: ArrayBuffer(EndPoint(DESKTOP-6IV0LP1,9093,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-02-19 02:44:52,418] WARN No meta.properties file under dir D:\tmp\kafka3-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-02-19 02:44:52,495] INFO [ExpirationReaper-3-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-02-19 02:44:52,512] INFO [ExpirationReaper-3-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-02-19 02:44:52,512] INFO [ExpirationReaper-3-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-02-19 02:44:52,527] INFO [GroupCoordinator 3]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-02-19 02:44:52,529] INFO [GroupCoordinator 3]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-02-19 02:44:52,535] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 7 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 02:44:52,565] INFO [ProducerId Manager 3]: Acquired new producerId block (brokerId:3,blockStartProducerId:2000,blockEndProducerId:2999) by writing to Zk with path version 3 (kafka.coordinator.transaction.ProducerIdManager)
[2019-02-19 02:44:52,584] INFO [TransactionCoordinator id=3] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-02-19 02:44:52,587] INFO [Transaction Marker Channel Manager 3]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-02-19 02:44:52,587] INFO [TransactionCoordinator id=3] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-02-19 02:44:52,628] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-02-19 02:44:52,639] INFO [SocketServer brokerId=3] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-02-19 02:44:52,644] INFO Kafka version : 2.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-02-19 02:44:52,644] INFO Kafka commitId : 809be928f1ae004e (org.apache.kafka.common.utils.AppInfoParser)
[2019-02-19 02:44:52,647] INFO [KafkaServer id=3] started (kafka.server.KafkaServer)
[2019-02-19 02:50:50,040] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:57264 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-02-19 02:50:50,045] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:57264 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-02-19 02:50:50,074] INFO Established session 0x10006c52e520003 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:57264 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-02-19 02:50:50,348] INFO Got user-level KeeperException when processing sessionid:0x10006c52e520003 type:setData cxid:0x6 zxid:0x3f txntype:-1 reqpath:n/a Error Path:/config/topics/test-cluster-topic Error:KeeperErrorCode = NoNode for /config/topics/test-cluster-topic (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-19 02:50:50,444] INFO Processed session termination for sessionid: 0x10006c52e520003 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-19 02:50:50,466] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:57264 which had sessionid 0x10006c52e520003 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-02-19 02:50:50,635] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(test-cluster-topic-2) (kafka.server.ReplicaFetcherManager)
[2019-02-19 02:50:50,604] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(test-cluster-topic-1) (kafka.server.ReplicaFetcherManager)
[2019-02-19 02:50:50,627] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(test-cluster-topic-3, test-cluster-topic-0) (kafka.server.ReplicaFetcherManager)
[2019-02-19 02:50:50,717] INFO [Log partition=test-cluster-topic-1, dir=D:\tmp\kafka1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 02:50:50,718] INFO [Log partition=test-cluster-topic-3, dir=D:\tmp\kafka3-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 02:50:50,730] INFO [Log partition=test-cluster-topic-3, dir=D:\tmp\kafka3-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 54 ms (kafka.log.Log)
[2019-02-19 02:50:50,732] INFO [Log partition=test-cluster-topic-2, dir=D:\tmp\kafka2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 02:50:50,733] INFO [Log partition=test-cluster-topic-1, dir=D:\tmp\kafka1-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 49 ms (kafka.log.Log)
[2019-02-19 02:50:50,734] INFO Created log for partition test-cluster-topic-3 in D:\tmp\kafka3-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 02:50:50,737] INFO [Partition test-cluster-topic-3 broker=3] No checkpointed highwatermark is found for partition test-cluster-topic-3 (kafka.cluster.Partition)
[2019-02-19 02:50:50,742] INFO Replica loaded for partition test-cluster-topic-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 02:50:50,742] INFO Created log for partition test-cluster-topic-1 in D:\tmp\kafka1-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 02:50:50,743] INFO Replica loaded for partition test-cluster-topic-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 02:50:50,744] INFO [Partition test-cluster-topic-1 broker=1] No checkpointed highwatermark is found for partition test-cluster-topic-1 (kafka.cluster.Partition)
[2019-02-19 02:50:50,745] INFO [Log partition=test-cluster-topic-2, dir=D:\tmp\kafka2-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 61 ms (kafka.log.Log)
[2019-02-19 02:50:50,744] INFO Replica loaded for partition test-cluster-topic-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 02:50:50,749] INFO Replica loaded for partition test-cluster-topic-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 02:50:50,750] INFO Created log for partition test-cluster-topic-2 in D:\tmp\kafka2-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 02:50:50,752] INFO [Partition test-cluster-topic-3 broker=3] test-cluster-topic-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 02:50:50,753] INFO Replica loaded for partition test-cluster-topic-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 02:50:50,753] INFO [Partition test-cluster-topic-2 broker=2] No checkpointed highwatermark is found for partition test-cluster-topic-2 (kafka.cluster.Partition)
[2019-02-19 02:50:50,753] INFO Replica loaded for partition test-cluster-topic-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 02:50:50,756] INFO Replica loaded for partition test-cluster-topic-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 02:50:50,757] INFO [Partition test-cluster-topic-1 broker=1] test-cluster-topic-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 02:50:50,760] INFO Replica loaded for partition test-cluster-topic-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 02:50:50,762] INFO Replica loaded for partition test-cluster-topic-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 02:50:50,770] INFO [Partition test-cluster-topic-2 broker=2] test-cluster-topic-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 02:50:50,849] INFO [Log partition=test-cluster-topic-0, dir=D:\tmp\kafka3-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 02:50:50,850] INFO [Log partition=test-cluster-topic-0, dir=D:\tmp\kafka3-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-02-19 02:50:50,851] INFO Created log for partition test-cluster-topic-0 in D:\tmp\kafka3-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 02:50:50,852] INFO [Partition test-cluster-topic-0 broker=3] No checkpointed highwatermark is found for partition test-cluster-topic-0 (kafka.cluster.Partition)
[2019-02-19 02:50:50,852] INFO Replica loaded for partition test-cluster-topic-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 02:50:50,853] INFO Replica loaded for partition test-cluster-topic-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 02:50:50,853] INFO Replica loaded for partition test-cluster-topic-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 02:50:50,853] INFO [Partition test-cluster-topic-0 broker=3] test-cluster-topic-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 02:50:50,863] INFO Replica loaded for partition test-cluster-topic-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 02:50:50,863] INFO Replica loaded for partition test-cluster-topic-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 02:50:50,882] INFO [Log partition=test-cluster-topic-2, dir=D:\tmp\kafka1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 02:50:50,883] INFO Replica loaded for partition test-cluster-topic-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 02:50:50,883] INFO [Log partition=test-cluster-topic-2, dir=D:\tmp\kafka1-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2019-02-19 02:50:50,885] INFO Created log for partition test-cluster-topic-2 in D:\tmp\kafka1-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 02:50:50,887] INFO [Log partition=test-cluster-topic-3, dir=D:\tmp\kafka2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 02:50:50,887] INFO [Partition test-cluster-topic-2 broker=1] No checkpointed highwatermark is found for partition test-cluster-topic-2 (kafka.cluster.Partition)
[2019-02-19 02:50:50,888] INFO [Log partition=test-cluster-topic-3, dir=D:\tmp\kafka2-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-02-19 02:50:50,888] INFO Replica loaded for partition test-cluster-topic-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 02:50:50,889] INFO Created log for partition test-cluster-topic-3 in D:\tmp\kafka2-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 02:50:50,889] INFO Replica loaded for partition test-cluster-topic-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 02:50:50,890] INFO Replica loaded for partition test-cluster-topic-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 02:50:50,890] INFO [Partition test-cluster-topic-3 broker=2] No checkpointed highwatermark is found for partition test-cluster-topic-3 (kafka.cluster.Partition)
[2019-02-19 02:50:50,890] INFO Replica loaded for partition test-cluster-topic-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 02:50:50,891] INFO Replica loaded for partition test-cluster-topic-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 02:50:50,894] INFO [Log partition=test-cluster-topic-3, dir=D:\tmp\kafka1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 02:50:50,893] INFO Replica loaded for partition test-cluster-topic-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 02:50:50,895] INFO [Log partition=test-cluster-topic-3, dir=D:\tmp\kafka1-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-02-19 02:50:50,894] INFO Replica loaded for partition test-cluster-topic-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 02:50:50,896] INFO Created log for partition test-cluster-topic-3 in D:\tmp\kafka1-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 02:50:50,897] INFO [Partition test-cluster-topic-3 broker=1] No checkpointed highwatermark is found for partition test-cluster-topic-3 (kafka.cluster.Partition)
[2019-02-19 02:50:50,897] INFO Replica loaded for partition test-cluster-topic-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 02:50:50,898] INFO Replica loaded for partition test-cluster-topic-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 02:50:50,900] INFO [Log partition=test-cluster-topic-0, dir=D:\tmp\kafka2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 02:50:50,901] INFO [Log partition=test-cluster-topic-0, dir=D:\tmp\kafka2-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-02-19 02:50:50,902] INFO Created log for partition test-cluster-topic-0 in D:\tmp\kafka2-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 02:50:50,903] INFO [Partition test-cluster-topic-0 broker=2] No checkpointed highwatermark is found for partition test-cluster-topic-0 (kafka.cluster.Partition)
[2019-02-19 02:50:50,905] INFO Replica loaded for partition test-cluster-topic-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 02:50:50,906] INFO Replica loaded for partition test-cluster-topic-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 02:50:50,906] INFO [Log partition=test-cluster-topic-0, dir=D:\tmp\kafka1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 02:50:50,906] INFO Replica loaded for partition test-cluster-topic-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 02:50:50,908] INFO [Log partition=test-cluster-topic-0, dir=D:\tmp\kafka1-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2019-02-19 02:50:50,910] INFO Created log for partition test-cluster-topic-0 in D:\tmp\kafka1-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 02:50:50,910] INFO [Log partition=test-cluster-topic-2, dir=D:\tmp\kafka3-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 02:50:50,911] INFO [Log partition=test-cluster-topic-1, dir=D:\tmp\kafka2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 02:50:50,911] INFO [Partition test-cluster-topic-0 broker=1] No checkpointed highwatermark is found for partition test-cluster-topic-0 (kafka.cluster.Partition)
[2019-02-19 02:50:50,911] INFO Replica loaded for partition test-cluster-topic-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 02:50:50,912] INFO Replica loaded for partition test-cluster-topic-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 02:50:50,912] INFO [Log partition=test-cluster-topic-2, dir=D:\tmp\kafka3-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-02-19 02:50:50,912] INFO [Log partition=test-cluster-topic-1, dir=D:\tmp\kafka2-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-02-19 02:50:50,914] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(test-cluster-topic-2, test-cluster-topic-0, test-cluster-topic-3) (kafka.server.ReplicaFetcherManager)
[2019-02-19 02:50:50,916] INFO Created log for partition test-cluster-topic-2 in D:\tmp\kafka3-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 02:50:50,915] INFO Created log for partition test-cluster-topic-1 in D:\tmp\kafka2-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 02:50:50,921] INFO [Partition test-cluster-topic-2 broker=3] No checkpointed highwatermark is found for partition test-cluster-topic-2 (kafka.cluster.Partition)
[2019-02-19 02:50:50,922] INFO [Partition test-cluster-topic-1 broker=2] No checkpointed highwatermark is found for partition test-cluster-topic-1 (kafka.cluster.Partition)
[2019-02-19 02:50:50,922] INFO Replica loaded for partition test-cluster-topic-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 02:50:50,922] INFO Replica loaded for partition test-cluster-topic-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 02:50:50,922] INFO Replica loaded for partition test-cluster-topic-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 02:50:50,924] INFO Replica loaded for partition test-cluster-topic-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 02:50:50,925] INFO Replica loaded for partition test-cluster-topic-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 02:50:50,927] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(test-cluster-topic-0, test-cluster-topic-1, test-cluster-topic-3) (kafka.server.ReplicaFetcherManager)
[2019-02-19 02:50:50,926] INFO Replica loaded for partition test-cluster-topic-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 02:50:50,935] INFO [Log partition=test-cluster-topic-1, dir=D:\tmp\kafka3-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 02:50:50,940] INFO [Log partition=test-cluster-topic-1, dir=D:\tmp\kafka3-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-02-19 02:50:50,942] INFO Created log for partition test-cluster-topic-1 in D:\tmp\kafka3-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 02:50:50,943] INFO [Partition test-cluster-topic-1 broker=3] No checkpointed highwatermark is found for partition test-cluster-topic-1 (kafka.cluster.Partition)
[2019-02-19 02:50:50,943] INFO Replica loaded for partition test-cluster-topic-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 02:50:50,946] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(test-cluster-topic-2, test-cluster-topic-1) (kafka.server.ReplicaFetcherManager)
[2019-02-19 02:50:50,963] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=3, host=DESKTOP-6IV0LP1:9093) for partitions Map(test-cluster-topic-0 -> (offset=0, leaderEpoch=0), test-cluster-topic-3 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-02-19 02:50:50,966] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-02-19 02:50:50,966] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-02-19 02:50:50,969] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=DESKTOP-6IV0LP1:9092) for partitions Map(test-cluster-topic-2 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-02-19 02:50:50,970] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=3, host=DESKTOP-6IV0LP1:9093) for partitions Map(test-cluster-topic-0 -> (offset=0, leaderEpoch=0), test-cluster-topic-3 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-02-19 02:50:50,974] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in test-cluster-topic-3. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-02-19 02:50:50,982] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-02-19 02:50:50,977] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=DESKTOP-6IV0LP1:9091) for partitions Map(test-cluster-topic-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-02-19 02:50:50,980] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in test-cluster-topic-3. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-02-19 02:50:50,983] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in test-cluster-topic-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-02-19 02:50:50,984] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-02-19 02:50:50,987] INFO [Log partition=test-cluster-topic-3, dir=D:\tmp\kafka2-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-02-19 02:50:50,983] INFO [Log partition=test-cluster-topic-3, dir=D:\tmp\kafka1-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-02-19 02:50:50,987] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in test-cluster-topic-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-02-19 02:50:50,988] INFO [Log partition=test-cluster-topic-1, dir=D:\tmp\kafka2-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-02-19 02:50:50,986] INFO [Log partition=test-cluster-topic-2, dir=D:\tmp\kafka1-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-02-19 02:50:50,989] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in test-cluster-topic-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-02-19 02:50:50,993] INFO [Log partition=test-cluster-topic-0, dir=D:\tmp\kafka1-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-02-19 02:50:50,988] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in test-cluster-topic-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-02-19 02:50:51,000] INFO [Log partition=test-cluster-topic-0, dir=D:\tmp\kafka2-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-02-19 02:50:51,036] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=1, host=DESKTOP-6IV0LP1:9091) for partitions Map(test-cluster-topic-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-02-19 02:50:51,048] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-02-19 02:50:51,058] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=2, host=DESKTOP-6IV0LP1:9092) for partitions Map(test-cluster-topic-2 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-02-19 02:50:51,066] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in test-cluster-topic-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-02-19 02:50:51,068] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-02-19 02:50:51,074] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in test-cluster-topic-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-02-19 02:50:51,076] INFO [Log partition=test-cluster-topic-2, dir=D:\tmp\kafka3-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-02-19 02:50:51,074] INFO [Log partition=test-cluster-topic-1, dir=D:\tmp\kafka3-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-02-19 02:50:51,075] ERROR [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error for partition test-cluster-topic-0 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2019-02-19 02:50:51,081] ERROR [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error for partition test-cluster-topic-3 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2019-02-19 02:50:51,073] ERROR [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error for partition test-cluster-topic-0 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2019-02-19 02:50:51,105] ERROR [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error for partition test-cluster-topic-3 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2019-02-19 02:54:24,870] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 02:54:43,461] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 02:54:52,529] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 02:56:47,489] INFO Accepted socket connection from /127.0.0.1:57291 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-02-19 02:56:47,494] INFO Client attempting to establish new session at /127.0.0.1:57291 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-02-19 02:56:47,516] INFO Established session 0x10006c52e520004 with negotiated timeout 30000 for client /127.0.0.1:57291 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-02-19 02:56:47,750] INFO Processed session termination for sessionid: 0x10006c52e520004 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-19 02:56:47,763] INFO Closed socket connection for client /127.0.0.1:57291 which had sessionid 0x10006c52e520004 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-02-19 02:58:38,525] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:57297 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-02-19 02:58:38,528] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:57297 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-02-19 02:58:38,551] INFO Established session 0x10006c52e520005 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:57297 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-02-19 02:58:38,822] INFO Got user-level KeeperException when processing sessionid:0x10006c52e520005 type:setData cxid:0x6 zxid:0x4f txntype:-1 reqpath:n/a Error Path:/config/topics/test-cluster-topic1 Error:KeeperErrorCode = NoNode for /config/topics/test-cluster-topic1 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-19 02:58:38,909] INFO Processed session termination for sessionid: 0x10006c52e520005 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-19 02:58:38,943] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:57297 which had sessionid 0x10006c52e520005 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-02-19 02:58:39,007] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(test-cluster-topic1-3, test-cluster-topic1-0) (kafka.server.ReplicaFetcherManager)
[2019-02-19 02:58:39,011] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(test-cluster-topic1-2) (kafka.server.ReplicaFetcherManager)
[2019-02-19 02:58:39,011] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(test-cluster-topic1-1) (kafka.server.ReplicaFetcherManager)
[2019-02-19 02:58:39,021] INFO [Log partition=test-cluster-topic1-3, dir=D:\tmp\kafka1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 02:58:39,025] INFO [Log partition=test-cluster-topic1-3, dir=D:\tmp\kafka1-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2019-02-19 02:58:39,026] INFO [Log partition=test-cluster-topic1-2, dir=D:\tmp\kafka3-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 02:58:39,028] INFO Created log for partition test-cluster-topic1-3 in D:\tmp\kafka1-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 02:58:39,029] INFO [Log partition=test-cluster-topic1-1, dir=D:\tmp\kafka2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 02:58:39,029] INFO [Log partition=test-cluster-topic1-2, dir=D:\tmp\kafka3-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-02-19 02:58:39,031] INFO [Log partition=test-cluster-topic1-1, dir=D:\tmp\kafka2-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-02-19 02:58:39,033] INFO Created log for partition test-cluster-topic1-2 in D:\tmp\kafka3-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 02:58:39,034] INFO [Partition test-cluster-topic1-3 broker=1] No checkpointed highwatermark is found for partition test-cluster-topic1-3 (kafka.cluster.Partition)
[2019-02-19 02:58:39,035] INFO Created log for partition test-cluster-topic1-1 in D:\tmp\kafka2-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 02:58:39,035] INFO Replica loaded for partition test-cluster-topic1-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 02:58:39,037] INFO [Partition test-cluster-topic1-1 broker=2] No checkpointed highwatermark is found for partition test-cluster-topic1-1 (kafka.cluster.Partition)
[2019-02-19 02:58:39,036] INFO Replica loaded for partition test-cluster-topic1-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 02:58:39,035] INFO [Partition test-cluster-topic1-2 broker=3] No checkpointed highwatermark is found for partition test-cluster-topic1-2 (kafka.cluster.Partition)
[2019-02-19 02:58:39,038] INFO Replica loaded for partition test-cluster-topic1-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 02:58:39,040] INFO Replica loaded for partition test-cluster-topic1-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 02:58:39,037] INFO Replica loaded for partition test-cluster-topic1-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 02:58:39,038] INFO [Partition test-cluster-topic1-3 broker=1] test-cluster-topic1-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 02:58:39,041] INFO Replica loaded for partition test-cluster-topic1-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 02:58:39,041] INFO [Partition test-cluster-topic1-2 broker=3] test-cluster-topic1-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 02:58:39,042] INFO [Partition test-cluster-topic1-1 broker=2] test-cluster-topic1-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 02:58:39,094] INFO [Log partition=test-cluster-topic1-0, dir=D:\tmp\kafka1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 02:58:39,095] INFO [Log partition=test-cluster-topic1-0, dir=D:\tmp\kafka1-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2019-02-19 02:58:39,097] INFO Created log for partition test-cluster-topic1-0 in D:\tmp\kafka1-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 02:58:39,099] INFO [Partition test-cluster-topic1-0 broker=1] No checkpointed highwatermark is found for partition test-cluster-topic1-0 (kafka.cluster.Partition)
[2019-02-19 02:58:39,099] INFO Replica loaded for partition test-cluster-topic1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 02:58:39,100] INFO Replica loaded for partition test-cluster-topic1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 02:58:39,101] INFO [Partition test-cluster-topic1-0 broker=1] test-cluster-topic1-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 02:58:39,111] INFO Replica loaded for partition test-cluster-topic1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 02:58:39,117] INFO [Log partition=test-cluster-topic1-0, dir=D:\tmp\kafka2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 02:58:39,120] INFO [Log partition=test-cluster-topic1-0, dir=D:\tmp\kafka2-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-02-19 02:58:39,122] INFO Created log for partition test-cluster-topic1-0 in D:\tmp\kafka2-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 02:58:39,123] INFO [Partition test-cluster-topic1-0 broker=2] No checkpointed highwatermark is found for partition test-cluster-topic1-0 (kafka.cluster.Partition)
[2019-02-19 02:58:39,124] INFO Replica loaded for partition test-cluster-topic1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 02:58:39,125] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(test-cluster-topic1-0) (kafka.server.ReplicaFetcherManager)
[2019-02-19 02:58:39,126] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=DESKTOP-6IV0LP1:9091) for partitions Map(test-cluster-topic1-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-02-19 02:58:39,128] INFO Replica loaded for partition test-cluster-topic1-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 02:58:39,134] INFO [Log partition=test-cluster-topic1-3, dir=D:\tmp\kafka3-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 02:58:39,135] INFO [Log partition=test-cluster-topic1-3, dir=D:\tmp\kafka3-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-02-19 02:58:39,137] INFO Created log for partition test-cluster-topic1-3 in D:\tmp\kafka3-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 02:58:39,138] INFO [Partition test-cluster-topic1-3 broker=3] No checkpointed highwatermark is found for partition test-cluster-topic1-3 (kafka.cluster.Partition)
[2019-02-19 02:58:39,139] INFO Replica loaded for partition test-cluster-topic1-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 02:58:39,140] INFO Replica loaded for partition test-cluster-topic1-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 02:58:39,144] INFO [Log partition=test-cluster-topic1-1, dir=D:\tmp\kafka3-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 02:58:39,145] INFO [Log partition=test-cluster-topic1-1, dir=D:\tmp\kafka3-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2019-02-19 02:58:39,146] INFO Created log for partition test-cluster-topic1-1 in D:\tmp\kafka3-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 02:58:39,147] INFO [Partition test-cluster-topic1-1 broker=3] No checkpointed highwatermark is found for partition test-cluster-topic1-1 (kafka.cluster.Partition)
[2019-02-19 02:58:39,147] INFO Replica loaded for partition test-cluster-topic1-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 02:58:39,148] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(test-cluster-topic1-3, test-cluster-topic1-1) (kafka.server.ReplicaFetcherManager)
[2019-02-19 02:58:39,150] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=1, host=DESKTOP-6IV0LP1:9091) for partitions Map(test-cluster-topic1-3 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-02-19 02:58:39,151] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=2, host=DESKTOP-6IV0LP1:9092) for partitions Map(test-cluster-topic1-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-02-19 02:58:39,159] INFO Replica loaded for partition test-cluster-topic1-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 02:58:39,162] INFO [Log partition=test-cluster-topic1-2, dir=D:\tmp\kafka1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 02:58:39,163] INFO [Log partition=test-cluster-topic1-2, dir=D:\tmp\kafka1-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2019-02-19 02:58:39,164] INFO Created log for partition test-cluster-topic1-2 in D:\tmp\kafka1-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 02:58:39,166] INFO [Partition test-cluster-topic1-2 broker=1] No checkpointed highwatermark is found for partition test-cluster-topic1-2 (kafka.cluster.Partition)
[2019-02-19 02:58:39,167] INFO Replica loaded for partition test-cluster-topic1-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 02:58:39,167] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(test-cluster-topic1-2) (kafka.server.ReplicaFetcherManager)
[2019-02-19 02:58:39,168] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=3, host=DESKTOP-6IV0LP1:9093) for partitions Map(test-cluster-topic1-2 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-02-19 02:58:39,488] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in test-cluster-topic1-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-02-19 02:58:39,489] INFO [Log partition=test-cluster-topic1-0, dir=D:\tmp\kafka2-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-02-19 02:58:39,516] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in test-cluster-topic1-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-02-19 02:58:39,516] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in test-cluster-topic1-3. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-02-19 02:58:39,517] INFO [Log partition=test-cluster-topic1-1, dir=D:\tmp\kafka3-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-02-19 02:58:39,519] INFO [Log partition=test-cluster-topic1-3, dir=D:\tmp\kafka3-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-02-19 02:58:39,668] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in test-cluster-topic1-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-02-19 02:58:39,669] INFO [Log partition=test-cluster-topic1-2, dir=D:\tmp\kafka1-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-02-19 02:58:52,530] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:57303 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-02-19 02:58:52,535] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:57303 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-02-19 02:58:52,557] INFO Established session 0x10006c52e520006 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:57303 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-02-19 02:58:52,810] INFO Processed session termination for sessionid: 0x10006c52e520006 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-19 02:58:52,826] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:57303 which had sessionid 0x10006c52e520006 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-02-19 03:04:24,870] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:04:43,462] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:04:52,529] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:14:24,869] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:14:43,462] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:14:52,529] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:24:24,868] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:24:43,461] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:24:52,529] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:25:58,438] INFO Got user-level KeeperException when processing sessionid:0x10006c52e520000 type:setData cxid:0x69 zxid:0x5e txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /config/topics/__consumer_offsets (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-19 03:25:58,478] INFO Topic creation Map(__consumer_offsets-22 -> ArrayBuffer(2), __consumer_offsets-30 -> ArrayBuffer(1), __consumer_offsets-8 -> ArrayBuffer(3), __consumer_offsets-21 -> ArrayBuffer(1), __consumer_offsets-4 -> ArrayBuffer(2), __consumer_offsets-27 -> ArrayBuffer(1), __consumer_offsets-7 -> ArrayBuffer(2), __consumer_offsets-9 -> ArrayBuffer(1), __consumer_offsets-46 -> ArrayBuffer(2), __consumer_offsets-25 -> ArrayBuffer(2), __consumer_offsets-35 -> ArrayBuffer(3), __consumer_offsets-41 -> ArrayBuffer(3), __consumer_offsets-33 -> ArrayBuffer(1), __consumer_offsets-23 -> ArrayBuffer(3), __consumer_offsets-49 -> ArrayBuffer(2), __consumer_offsets-47 -> ArrayBuffer(3), __consumer_offsets-16 -> ArrayBuffer(2), __consumer_offsets-28 -> ArrayBuffer(2), __consumer_offsets-31 -> ArrayBuffer(2), __consumer_offsets-36 -> ArrayBuffer(1), __consumer_offsets-42 -> ArrayBuffer(1), __consumer_offsets-3 -> ArrayBuffer(1), __consumer_offsets-18 -> ArrayBuffer(1), __consumer_offsets-37 -> ArrayBuffer(2), __consumer_offsets-15 -> ArrayBuffer(1), __consumer_offsets-24 -> ArrayBuffer(1), __consumer_offsets-38 -> ArrayBuffer(3), __consumer_offsets-17 -> ArrayBuffer(3), __consumer_offsets-48 -> ArrayBuffer(1), __consumer_offsets-19 -> ArrayBuffer(2), __consumer_offsets-11 -> ArrayBuffer(3), __consumer_offsets-13 -> ArrayBuffer(2), __consumer_offsets-2 -> ArrayBuffer(3), __consumer_offsets-43 -> ArrayBuffer(2), __consumer_offsets-6 -> ArrayBuffer(1), __consumer_offsets-14 -> ArrayBuffer(3), __consumer_offsets-20 -> ArrayBuffer(3), __consumer_offsets-0 -> ArrayBuffer(1), __consumer_offsets-44 -> ArrayBuffer(3), __consumer_offsets-39 -> ArrayBuffer(1), __consumer_offsets-12 -> ArrayBuffer(1), __consumer_offsets-45 -> ArrayBuffer(1), __consumer_offsets-1 -> ArrayBuffer(2), __consumer_offsets-5 -> ArrayBuffer(3), __consumer_offsets-26 -> ArrayBuffer(3), __consumer_offsets-29 -> ArrayBuffer(3), __consumer_offsets-34 -> ArrayBuffer(2), __consumer_offsets-10 -> ArrayBuffer(2), __consumer_offsets-32 -> ArrayBuffer(3), __consumer_offsets-40 -> ArrayBuffer(2)) (kafka.zk.AdminZkClient)
[2019-02-19 03:25:58,501] INFO [KafkaApi-1] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2019-02-19 03:25:58,871] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-7, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-49, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-37, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-02-19 03:25:58,881] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 03:25:58,887] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka2-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2019-02-19 03:25:58,889] INFO Created log for partition __consumer_offsets-10 in D:\tmp\kafka2-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 03:25:58,892] INFO [Partition __consumer_offsets-10 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2019-02-19 03:25:58,893] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 03:25:58,893] INFO [Partition __consumer_offsets-10 broker=2] __consumer_offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 03:25:58,867] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(__consumer_offsets-30, __consumer_offsets-21, __consumer_offsets-27, __consumer_offsets-9, __consumer_offsets-33, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-48, __consumer_offsets-6, __consumer_offsets-0, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45) (kafka.server.ReplicaFetcherManager)
[2019-02-19 03:25:58,909] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 03:25:58,935] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka1-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 29 ms (kafka.log.Log)
[2019-02-19 03:25:58,937] INFO Created log for partition __consumer_offsets-0 in D:\tmp\kafka1-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 03:25:58,938] INFO [Partition __consumer_offsets-0 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2019-02-19 03:25:58,940] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 03:25:58,941] INFO [Partition __consumer_offsets-0 broker=1] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 03:25:58,929] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(__consumer_offsets-8, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-23, __consumer_offsets-47, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-11, __consumer_offsets-2, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-44, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-32) (kafka.server.ReplicaFetcherManager)
[2019-02-19 03:25:58,958] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka3-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 03:25:58,959] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka3-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-02-19 03:25:58,960] INFO Created log for partition __consumer_offsets-29 in D:\tmp\kafka3-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 03:25:58,961] INFO [Partition __consumer_offsets-29 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[2019-02-19 03:25:58,961] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 03:25:58,961] INFO [Partition __consumer_offsets-29 broker=3] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 03:25:58,963] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 03:25:58,964] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka2-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-02-19 03:25:58,965] INFO Created log for partition __consumer_offsets-7 in D:\tmp\kafka2-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 03:25:58,967] INFO [Partition __consumer_offsets-7 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2019-02-19 03:25:58,967] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 03:25:58,968] INFO [Partition __consumer_offsets-7 broker=2] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 03:25:59,002] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 03:25:59,003] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka1-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-02-19 03:25:59,004] INFO Created log for partition __consumer_offsets-48 in D:\tmp\kafka1-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 03:25:59,005] INFO [Partition __consumer_offsets-48 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2019-02-19 03:25:59,006] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 03:25:59,006] INFO [Partition __consumer_offsets-48 broker=1] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 03:25:59,043] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka3-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 03:25:59,043] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 03:25:59,044] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka3-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-02-19 03:25:59,046] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka2-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-02-19 03:25:59,046] INFO Created log for partition __consumer_offsets-26 in D:\tmp\kafka3-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 03:25:59,047] INFO Created log for partition __consumer_offsets-4 in D:\tmp\kafka2-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 03:25:59,049] INFO [Partition __consumer_offsets-4 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2019-02-19 03:25:59,050] INFO [Partition __consumer_offsets-26 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2019-02-19 03:25:59,050] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 03:25:59,050] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 03:25:59,051] INFO [Partition __consumer_offsets-4 broker=2] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 03:25:59,051] INFO [Partition __consumer_offsets-26 broker=3] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 03:25:59,062] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 03:25:59,063] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka1-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2019-02-19 03:25:59,067] INFO Created log for partition __consumer_offsets-45 in D:\tmp\kafka1-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 03:25:59,068] INFO [Partition __consumer_offsets-45 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2019-02-19 03:25:59,068] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 03:25:59,069] INFO [Partition __consumer_offsets-45 broker=1] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 03:25:59,112] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 03:25:59,112] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka2-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2019-02-19 03:25:59,113] INFO Created log for partition __consumer_offsets-1 in D:\tmp\kafka2-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 03:25:59,115] INFO [Partition __consumer_offsets-1 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[2019-02-19 03:25:59,115] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 03:25:59,115] INFO [Partition __consumer_offsets-1 broker=2] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 03:25:59,143] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 03:25:59,143] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka3-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 03:25:59,144] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka3-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-02-19 03:25:59,144] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka1-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-02-19 03:25:59,145] INFO Created log for partition __consumer_offsets-23 in D:\tmp\kafka3-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 03:25:59,146] INFO Created log for partition __consumer_offsets-42 in D:\tmp\kafka1-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 03:25:59,146] INFO [Partition __consumer_offsets-23 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2019-02-19 03:25:59,147] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 03:25:59,148] INFO [Partition __consumer_offsets-23 broker=3] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 03:25:59,148] INFO [Partition __consumer_offsets-42 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2019-02-19 03:25:59,149] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 03:25:59,150] INFO [Partition __consumer_offsets-42 broker=1] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 03:25:59,162] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 03:25:59,163] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka2-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2019-02-19 03:25:59,164] INFO Created log for partition __consumer_offsets-49 in D:\tmp\kafka2-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 03:25:59,166] INFO [Partition __consumer_offsets-49 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2019-02-19 03:25:59,167] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 03:25:59,167] INFO [Partition __consumer_offsets-49 broker=2] __consumer_offsets-49 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 03:25:59,204] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka3-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 03:25:59,205] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka3-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-02-19 03:25:59,206] INFO Created log for partition __consumer_offsets-20 in D:\tmp\kafka3-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 03:25:59,207] INFO [Partition __consumer_offsets-20 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2019-02-19 03:25:59,207] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 03:25:59,208] INFO [Partition __consumer_offsets-20 broker=3] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 03:25:59,240] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 03:25:59,241] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka2-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2019-02-19 03:25:59,242] INFO Created log for partition __consumer_offsets-46 in D:\tmp\kafka2-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 03:25:59,243] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 03:25:59,244] INFO [Partition __consumer_offsets-46 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2019-02-19 03:25:59,245] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka1-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-02-19 03:25:59,245] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 03:25:59,246] INFO [Partition __consumer_offsets-46 broker=2] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 03:25:59,246] INFO Created log for partition __consumer_offsets-39 in D:\tmp\kafka1-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 03:25:59,247] INFO [Partition __consumer_offsets-39 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2019-02-19 03:25:59,247] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 03:25:59,248] INFO [Partition __consumer_offsets-39 broker=1] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 03:25:59,277] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka3-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 03:25:59,278] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka3-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2019-02-19 03:25:59,279] INFO Created log for partition __consumer_offsets-17 in D:\tmp\kafka3-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 03:25:59,281] INFO [Partition __consumer_offsets-17 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2019-02-19 03:25:59,281] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 03:25:59,281] INFO [Partition __consumer_offsets-17 broker=3] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 03:25:59,309] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 03:25:59,309] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 03:25:59,310] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka1-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2019-02-19 03:25:59,310] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka2-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2019-02-19 03:25:59,312] INFO Created log for partition __consumer_offsets-43 in D:\tmp\kafka2-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 03:25:59,312] INFO Created log for partition __consumer_offsets-36 in D:\tmp\kafka1-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 03:25:59,315] INFO [Partition __consumer_offsets-43 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2019-02-19 03:25:59,315] INFO [Partition __consumer_offsets-36 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2019-02-19 03:25:59,315] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 03:25:59,315] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 03:25:59,316] INFO [Partition __consumer_offsets-43 broker=2] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 03:25:59,317] INFO [Partition __consumer_offsets-36 broker=1] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 03:25:59,329] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka3-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 03:25:59,330] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka3-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2019-02-19 03:25:59,331] INFO Created log for partition __consumer_offsets-14 in D:\tmp\kafka3-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 03:25:59,334] INFO [Partition __consumer_offsets-14 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2019-02-19 03:25:59,334] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 03:25:59,335] INFO [Partition __consumer_offsets-14 broker=3] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 03:25:59,393] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 03:25:59,395] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka1-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-02-19 03:25:59,396] INFO Created log for partition __consumer_offsets-33 in D:\tmp\kafka1-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 03:25:59,397] INFO [Partition __consumer_offsets-33 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2019-02-19 03:25:59,397] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 03:25:59,397] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 03:25:59,398] INFO [Partition __consumer_offsets-33 broker=1] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 03:25:59,399] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka2-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-02-19 03:25:59,400] INFO Created log for partition __consumer_offsets-40 in D:\tmp\kafka2-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 03:25:59,401] INFO [Partition __consumer_offsets-40 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2019-02-19 03:25:59,401] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 03:25:59,403] INFO [Partition __consumer_offsets-40 broker=2] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 03:25:59,422] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka3-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 03:25:59,422] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka3-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2019-02-19 03:25:59,423] INFO Created log for partition __consumer_offsets-11 in D:\tmp\kafka3-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 03:25:59,425] INFO [Partition __consumer_offsets-11 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2019-02-19 03:25:59,425] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 03:25:59,425] INFO [Partition __consumer_offsets-11 broker=3] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 03:25:59,448] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 03:25:59,449] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka1-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2019-02-19 03:25:59,450] INFO Created log for partition __consumer_offsets-30 in D:\tmp\kafka1-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 03:25:59,452] INFO [Partition __consumer_offsets-30 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2019-02-19 03:25:59,454] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 03:25:59,454] INFO [Partition __consumer_offsets-30 broker=1] __consumer_offsets-30 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 03:25:59,503] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka3-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 03:25:59,504] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka3-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2019-02-19 03:25:59,505] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 03:25:59,506] INFO Created log for partition __consumer_offsets-8 in D:\tmp\kafka3-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 03:25:59,506] INFO [Partition __consumer_offsets-8 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2019-02-19 03:25:59,507] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 03:25:59,507] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka2-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-02-19 03:25:59,508] INFO [Partition __consumer_offsets-8 broker=3] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 03:25:59,509] INFO Created log for partition __consumer_offsets-37 in D:\tmp\kafka2-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 03:25:59,510] INFO [Partition __consumer_offsets-37 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2019-02-19 03:25:59,510] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 03:25:59,510] INFO [Partition __consumer_offsets-37 broker=2] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 03:25:59,529] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 03:25:59,530] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka1-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2019-02-19 03:25:59,531] INFO Created log for partition __consumer_offsets-27 in D:\tmp\kafka1-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 03:25:59,533] INFO [Partition __consumer_offsets-27 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2019-02-19 03:25:59,533] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 03:25:59,533] INFO [Partition __consumer_offsets-27 broker=1] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 03:25:59,557] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka3-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 03:25:59,557] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka3-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2019-02-19 03:25:59,558] INFO Created log for partition __consumer_offsets-5 in D:\tmp\kafka3-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 03:25:59,560] INFO [Partition __consumer_offsets-5 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[2019-02-19 03:25:59,560] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 03:25:59,560] INFO [Partition __consumer_offsets-5 broker=3] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 03:25:59,589] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 03:25:59,590] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka2-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-02-19 03:25:59,591] INFO Created log for partition __consumer_offsets-34 in D:\tmp\kafka2-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 03:25:59,593] INFO [Partition __consumer_offsets-34 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2019-02-19 03:25:59,593] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 03:25:59,593] INFO [Partition __consumer_offsets-34 broker=2] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 03:25:59,627] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 03:25:59,628] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka1-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-02-19 03:25:59,629] INFO Created log for partition __consumer_offsets-24 in D:\tmp\kafka1-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 03:25:59,631] INFO [Partition __consumer_offsets-24 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2019-02-19 03:25:59,631] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 03:25:59,631] INFO [Partition __consumer_offsets-24 broker=1] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 03:25:59,647] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka3-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 03:25:59,648] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka3-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2019-02-19 03:25:59,649] INFO Created log for partition __consumer_offsets-2 in D:\tmp\kafka3-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 03:25:59,651] INFO [Partition __consumer_offsets-2 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2019-02-19 03:25:59,651] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 03:25:59,652] INFO [Partition __consumer_offsets-2 broker=3] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 03:25:59,686] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 03:25:59,687] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka2-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-02-19 03:25:59,688] INFO Created log for partition __consumer_offsets-31 in D:\tmp\kafka2-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 03:25:59,690] INFO [Partition __consumer_offsets-31 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2019-02-19 03:25:59,690] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 03:25:59,690] INFO [Partition __consumer_offsets-31 broker=2] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 03:25:59,716] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka3-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 03:25:59,716] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka3-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2019-02-19 03:25:59,717] INFO Created log for partition __consumer_offsets-47 in D:\tmp\kafka3-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 03:25:59,718] INFO [Partition __consumer_offsets-47 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2019-02-19 03:25:59,719] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 03:25:59,719] INFO [Partition __consumer_offsets-47 broker=3] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 03:25:59,726] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 03:25:59,727] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka1-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2019-02-19 03:25:59,728] INFO Created log for partition __consumer_offsets-21 in D:\tmp\kafka1-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 03:25:59,730] INFO [Partition __consumer_offsets-21 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2019-02-19 03:25:59,730] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 03:25:59,731] INFO [Partition __consumer_offsets-21 broker=1] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 03:25:59,806] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 03:25:59,806] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka2-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2019-02-19 03:25:59,807] INFO Created log for partition __consumer_offsets-19 in D:\tmp\kafka2-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 03:25:59,809] INFO [Partition __consumer_offsets-19 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2019-02-19 03:25:59,809] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 03:25:59,809] INFO [Partition __consumer_offsets-19 broker=2] __consumer_offsets-19 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 03:25:59,847] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka3-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 03:25:59,848] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka3-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2019-02-19 03:25:59,849] INFO Created log for partition __consumer_offsets-38 in D:\tmp\kafka3-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 03:25:59,851] INFO [Partition __consumer_offsets-38 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2019-02-19 03:25:59,851] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 03:25:59,851] INFO [Partition __consumer_offsets-38 broker=3] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 03:25:59,855] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 03:25:59,856] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka1-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2019-02-19 03:25:59,856] INFO Created log for partition __consumer_offsets-18 in D:\tmp\kafka1-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 03:25:59,858] INFO [Partition __consumer_offsets-18 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2019-02-19 03:25:59,858] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 03:25:59,859] INFO [Partition __consumer_offsets-18 broker=1] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 03:25:59,873] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 03:25:59,874] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka2-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2019-02-19 03:25:59,875] INFO Created log for partition __consumer_offsets-28 in D:\tmp\kafka2-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 03:25:59,877] INFO [Partition __consumer_offsets-28 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2019-02-19 03:25:59,877] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 03:25:59,877] INFO [Partition __consumer_offsets-28 broker=2] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 03:25:59,910] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka3-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 03:25:59,911] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka3-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2019-02-19 03:25:59,912] INFO Created log for partition __consumer_offsets-35 in D:\tmp\kafka3-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 03:25:59,914] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 03:25:59,914] INFO [Partition __consumer_offsets-35 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2019-02-19 03:25:59,914] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 03:25:59,915] INFO [Partition __consumer_offsets-35 broker=3] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 03:25:59,915] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka1-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-02-19 03:25:59,918] INFO Created log for partition __consumer_offsets-15 in D:\tmp\kafka1-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 03:25:59,918] INFO [Partition __consumer_offsets-15 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2019-02-19 03:25:59,919] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 03:25:59,919] INFO [Partition __consumer_offsets-15 broker=1] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 03:25:59,948] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 03:25:59,949] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka2-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-02-19 03:25:59,950] INFO Created log for partition __consumer_offsets-25 in D:\tmp\kafka2-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 03:25:59,952] INFO [Partition __consumer_offsets-25 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2019-02-19 03:25:59,952] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 03:25:59,953] INFO [Partition __consumer_offsets-25 broker=2] __consumer_offsets-25 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 03:25:59,975] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka3-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 03:25:59,976] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka3-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2019-02-19 03:25:59,977] INFO Created log for partition __consumer_offsets-44 in D:\tmp\kafka3-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 03:25:59,978] INFO [Partition __consumer_offsets-44 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2019-02-19 03:25:59,978] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 03:25:59,979] INFO [Partition __consumer_offsets-44 broker=3] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 03:26:00,010] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 03:26:00,011] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka1-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2019-02-19 03:26:00,012] INFO Created log for partition __consumer_offsets-12 in D:\tmp\kafka1-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 03:26:00,013] INFO [Partition __consumer_offsets-12 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2019-02-19 03:26:00,013] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 03:26:00,014] INFO [Partition __consumer_offsets-12 broker=1] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 03:26:00,037] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 03:26:00,037] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka3-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 03:26:00,038] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka2-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 26 ms (kafka.log.Log)
[2019-02-19 03:26:00,039] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka3-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2019-02-19 03:26:00,040] INFO Created log for partition __consumer_offsets-16 in D:\tmp\kafka2-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 03:26:00,040] INFO Created log for partition __consumer_offsets-32 in D:\tmp\kafka3-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 03:26:00,043] INFO [Partition __consumer_offsets-16 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2019-02-19 03:26:00,043] INFO [Partition __consumer_offsets-32 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2019-02-19 03:26:00,044] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 03:26:00,044] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 03:26:00,044] INFO [Partition __consumer_offsets-16 broker=2] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 03:26:00,045] INFO [Partition __consumer_offsets-32 broker=3] __consumer_offsets-32 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 03:26:00,075] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 03:26:00,076] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka1-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2019-02-19 03:26:00,077] INFO Created log for partition __consumer_offsets-9 in D:\tmp\kafka1-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 03:26:00,079] INFO [Partition __consumer_offsets-9 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2019-02-19 03:26:00,079] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 03:26:00,080] INFO [Partition __consumer_offsets-9 broker=1] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 03:26:00,110] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 03:26:00,111] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka2-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2019-02-19 03:26:00,111] INFO Created log for partition __consumer_offsets-22 in D:\tmp\kafka2-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 03:26:00,112] INFO [Partition __consumer_offsets-22 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2019-02-19 03:26:00,114] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 03:26:00,114] INFO [Partition __consumer_offsets-22 broker=2] __consumer_offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 03:26:00,135] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 03:26:00,135] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka3-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 03:26:00,136] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka1-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2019-02-19 03:26:00,137] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka3-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-02-19 03:26:00,138] INFO Created log for partition __consumer_offsets-6 in D:\tmp\kafka1-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 03:26:00,141] INFO [Partition __consumer_offsets-6 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2019-02-19 03:26:00,141] INFO Created log for partition __consumer_offsets-41 in D:\tmp\kafka3-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 03:26:00,141] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 03:26:00,142] INFO [Partition __consumer_offsets-6 broker=1] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 03:26:00,142] INFO [Partition __consumer_offsets-41 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2019-02-19 03:26:00,142] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 03:26:00,143] INFO [Partition __consumer_offsets-41 broker=3] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 03:26:00,157] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 03:26:00,158] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka2-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-02-19 03:26:00,158] INFO Created log for partition __consumer_offsets-13 in D:\tmp\kafka2-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 03:26:00,160] INFO [Partition __consumer_offsets-13 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2019-02-19 03:26:00,160] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 03:26:00,161] INFO [Partition __consumer_offsets-13 broker=2] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 03:26:00,211] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-02-19 03:26:00,212] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka1-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-02-19 03:26:00,213] INFO Created log for partition __consumer_offsets-3 in D:\tmp\kafka1-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-02-19 03:26:00,214] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,215] INFO [Partition __consumer_offsets-3 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2019-02-19 03:26:00,215] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,215] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-02-19 03:26:00,217] INFO [Partition __consumer_offsets-3 broker=1] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-02-19 03:26:00,217] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,218] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,218] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,218] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,219] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,219] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,219] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,219] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,220] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,220] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-22 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,220] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,220] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,221] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,221] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,221] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,222] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,222] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,222] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,223] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-31 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,223] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,224] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-37 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,227] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,226] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,227] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,228] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,229] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,230] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,230] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,230] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,231] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,231] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,231] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,231] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,232] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,232] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,232] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,232] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,233] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,233] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,234] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,234] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,235] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,235] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,235] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,235] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-2 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,236] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,237] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,237] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,240] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,240] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,241] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,241] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,242] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-14 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,242] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,242] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,243] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-23 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,246] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,249] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-29 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,251] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,252] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-35 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,252] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,252] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,253] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,253] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,253] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,255] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,255] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,257] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,257] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,257] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,257] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,258] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,258] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,258] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,259] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,259] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,260] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,261] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,261] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,261] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,261] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,262] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,262] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,262] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,263] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,265] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,266] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,267] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,267] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,268] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,268] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,269] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,269] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,270] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,270] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,271] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,271] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,272] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:26:00,323] INFO [GroupCoordinator 3]: Preparing to rebalance group console-consumer-47624 in state PreparingRebalance with old generation 0 (__consumer_offsets-44) (reason: Adding new member consumer-1-59b6a55a-d4e0-403e-b5c9-146bc8e09b47) (kafka.coordinator.group.GroupCoordinator)
[2019-02-19 03:26:00,330] INFO [GroupCoordinator 3]: Stabilized group console-consumer-47624 generation 1 (__consumer_offsets-44) (kafka.coordinator.group.GroupCoordinator)
[2019-02-19 03:26:00,341] INFO [GroupCoordinator 3]: Assignment received from leader for group console-consumer-47624 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-02-19 03:34:24,870] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:34:43,461] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:34:52,536] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:44:24,869] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:44:43,461] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:44:52,529] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:47:16,989] INFO [GroupCoordinator 3]: Preparing to rebalance group console-consumer-47624 in state PreparingRebalance with old generation 1 (__consumer_offsets-44) (reason: removing member consumer-1-59b6a55a-d4e0-403e-b5c9-146bc8e09b47 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-02-19 03:47:16,993] INFO [GroupCoordinator 3]: Group console-consumer-47624 with generation 2 is now empty (__consumer_offsets-44) (kafka.coordinator.group.GroupCoordinator)
[2019-02-19 03:48:01,415] INFO [GroupCoordinator 1]: Preparing to rebalance group test-group in state PreparingRebalance with old generation 0 (__consumer_offsets-12) (reason: Adding new member consumer-1-6a1d2417-60c2-4ed0-93e3-733af9e2a8ab) (kafka.coordinator.group.GroupCoordinator)
[2019-02-19 03:48:01,452] INFO [GroupCoordinator 1]: Stabilized group test-group generation 1 (__consumer_offsets-12) (kafka.coordinator.group.GroupCoordinator)
[2019-02-19 03:48:01,461] INFO [GroupCoordinator 1]: Assignment received from leader for group test-group for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-02-19 03:50:17,534] INFO [GroupCoordinator 1]: Preparing to rebalance group test-group in state PreparingRebalance with old generation 1 (__consumer_offsets-12) (reason: removing member consumer-1-6a1d2417-60c2-4ed0-93e3-733af9e2a8ab on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-02-19 03:50:17,536] INFO [GroupCoordinator 1]: Group test-group with generation 2 is now empty (__consumer_offsets-12) (kafka.coordinator.group.GroupCoordinator)
[2019-02-19 03:50:29,002] INFO [GroupCoordinator 2]: Preparing to rebalance group console-consumer-47013 in state PreparingRebalance with old generation 0 (__consumer_offsets-46) (reason: Adding new member consumer-1-cc57d1b9-10f5-41ec-ab34-ce7f5abd1cd4) (kafka.coordinator.group.GroupCoordinator)
[2019-02-19 03:50:29,009] INFO [GroupCoordinator 2]: Stabilized group console-consumer-47013 generation 1 (__consumer_offsets-46) (kafka.coordinator.group.GroupCoordinator)
[2019-02-19 03:50:29,017] INFO [GroupCoordinator 2]: Assignment received from leader for group console-consumer-47013 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-02-19 03:51:48,351] WARN Exception causing close of session 0x10006c52e520002: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2019-02-19 03:51:48,353] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=192961805, epoch=7288) to node 3: java.io.IOException: Connection to 3 was disconnected before the response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-02-19 03:51:48,354] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:57222 which had sessionid 0x10006c52e520002 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-02-19 03:51:48,354] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=168335184, epoch=7286) to node 3: java.io.IOException: Connection to 3 was disconnected before the response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-02-19 03:51:48,356] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=192961805, epoch=7288)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 3 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:97)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:97)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-02-19 03:51:48,357] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=168335184, epoch=7286)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 3 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:97)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:97)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-02-19 03:51:51,363] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Connection to node 3 (DESKTOP-6IV0LP1/192.168.56.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-02-19 03:51:51,365] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Connection to node 3 (DESKTOP-6IV0LP1/192.168.56.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-02-19 03:51:51,364] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=168335184, epoch=INITIAL) to node 3: java.io.IOException: Connection to DESKTOP-6IV0LP1:9093 (id: 3 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-02-19 03:51:51,365] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=192961805, epoch=INITIAL) to node 3: java.io.IOException: Connection to DESKTOP-6IV0LP1:9093 (id: 3 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-02-19 03:51:51,366] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={test-cluster-topic-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0]), test-cluster-topic-3=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=168335184, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to DESKTOP-6IV0LP1:9093 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-02-19 03:51:51,371] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={test-cluster-topic-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0]), test-cluster-topic1-2=(offset=2, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0]), test-cluster-topic-3=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=192961805, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to DESKTOP-6IV0LP1:9093 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-02-19 03:51:54,373] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Connection to node 3 (DESKTOP-6IV0LP1/192.168.56.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-02-19 03:51:54,374] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Connection to node 3 (DESKTOP-6IV0LP1/192.168.56.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-02-19 03:51:54,373] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=168335184, epoch=INITIAL) to node 3: java.io.IOException: Connection to DESKTOP-6IV0LP1:9093 (id: 3 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-02-19 03:51:54,375] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=192961805, epoch=INITIAL) to node 3: java.io.IOException: Connection to DESKTOP-6IV0LP1:9093 (id: 3 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-02-19 03:51:54,377] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={test-cluster-topic-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0]), test-cluster-topic-3=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=168335184, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to DESKTOP-6IV0LP1:9093 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-02-19 03:51:54,380] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={test-cluster-topic-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0]), test-cluster-topic1-2=(offset=2, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0]), test-cluster-topic-3=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=192961805, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to DESKTOP-6IV0LP1:9093 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-02-19 03:51:55,490] INFO Expiring session 0x10006c52e520002, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-02-19 03:51:55,491] INFO Processed session termination for sessionid: 0x10006c52e520002 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-02-19 03:51:55,606] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(test-cluster-topic-3) (kafka.server.ReplicaFetcherManager)
[2019-02-19 03:51:55,611] INFO [Partition test-cluster-topic-3 broker=2] test-cluster-topic-3 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-02-19 03:51:55,608] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(test-cluster-topic1-2, test-cluster-topic-0) (kafka.server.ReplicaFetcherManager)
[2019-02-19 03:51:55,612] INFO [Partition test-cluster-topic1-2 broker=1] test-cluster-topic1-2 starts at Leader Epoch 1 from offset 2. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-02-19 03:51:55,664] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(test-cluster-topic-0) (kafka.server.ReplicaFetcherManager)
[2019-02-19 03:51:55,665] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=DESKTOP-6IV0LP1:9091) for partitions Map(test-cluster-topic-0 -> (offset=0, leaderEpoch=1)) (kafka.server.ReplicaFetcherManager)
[2019-02-19 03:51:55,666] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2019-02-19 03:51:55,670] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2019-02-19 03:51:55,670] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2019-02-19 03:51:55,682] INFO [Partition test-cluster-topic-0 broker=1] test-cluster-topic-0 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-02-19 03:51:55,736] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(test-cluster-topic-2, test-cluster-topic1-1) (kafka.server.ReplicaFetcherManager)
[2019-02-19 03:51:55,739] INFO [Partition test-cluster-topic-2 broker=2] test-cluster-topic-2 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-02-19 03:51:55,741] WARN [LeaderEpochCache test-cluster-topic-2] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-02-19 03:51:55,738] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(test-cluster-topic-3) (kafka.server.ReplicaFetcherManager)
[2019-02-19 03:51:55,743] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=DESKTOP-6IV0LP1:9092) for partitions Map(test-cluster-topic-3 -> (offset=0, leaderEpoch=1)) (kafka.server.ReplicaFetcherManager)
[2019-02-19 03:51:55,743] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2019-02-19 03:51:55,747] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2019-02-19 03:51:55,747] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2019-02-19 03:51:55,753] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(test-cluster-topic1-3, test-cluster-topic-1) (kafka.server.ReplicaFetcherManager)
[2019-02-19 03:51:55,753] INFO [Partition test-cluster-topic1-3 broker=1] test-cluster-topic1-3 starts at Leader Epoch 1 from offset 2. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-02-19 03:51:55,769] INFO [Partition test-cluster-topic1-1 broker=2] test-cluster-topic1-1 starts at Leader Epoch 1 from offset 1. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-02-19 03:51:55,812] INFO [Partition test-cluster-topic-1 broker=1] test-cluster-topic-1 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-02-19 03:51:55,814] WARN [LeaderEpochCache test-cluster-topic-1] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-02-19 03:51:55,827] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(test-cluster-topic-1) (kafka.server.ReplicaFetcherManager)
[2019-02-19 03:51:55,828] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=DESKTOP-6IV0LP1:9091) for partitions Map(test-cluster-topic-1 -> (offset=0, leaderEpoch=1)) (kafka.server.ReplicaFetcherManager)
[2019-02-19 03:51:55,845] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(test-cluster-topic-2) (kafka.server.ReplicaFetcherManager)
[2019-02-19 03:51:55,845] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=DESKTOP-6IV0LP1:9092) for partitions Map(test-cluster-topic-2 -> (offset=0, leaderEpoch=1)) (kafka.server.ReplicaFetcherManager)
[2019-02-19 03:51:55,990] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in test-cluster-topic-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-02-19 03:51:55,990] INFO [Log partition=test-cluster-topic-0, dir=D:\tmp\kafka2-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-02-19 03:51:55,992] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in test-cluster-topic-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-02-19 03:51:55,994] INFO [Log partition=test-cluster-topic-1, dir=D:\tmp\kafka2-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-02-19 03:51:56,080] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in test-cluster-topic-3. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-02-19 03:51:56,081] INFO [Log partition=test-cluster-topic-3, dir=D:\tmp\kafka1-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-02-19 03:51:56,083] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in test-cluster-topic-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-02-19 03:51:56,085] INFO [Log partition=test-cluster-topic-2, dir=D:\tmp\kafka1-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-02-19 03:54:24,877] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 8 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:54:43,467] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-02-19 03:54:49,867] WARN Exception causing close of session 0x10006c52e520000: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2019-02-19 03:54:49,869] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:57193 which had sessionid 0x10006c52e520000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-02-19 03:54:49,868] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=698787398, epoch=7651) to node 1: java.io.IOException: Connection to 1 was disconnected before the response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-02-19 03:54:49,871] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=698787398, epoch=7651)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 1 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:97)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:97)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-02-19 03:54:51,092] WARN Exception causing close of session 0x10006c52e520001: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2019-02-19 03:54:51,092] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:57211 which had sessionid 0x10006c52e520001 (org.apache.zookeeper.server.NIOServerCnxn)
